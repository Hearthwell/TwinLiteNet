{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 10:43:34.156098: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-20 10:43:34.156126: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-20 10:43:34.156915: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-20 10:43:34.162697: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-20 10:43:35.114843: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from nobuco import pytorch_to_keras, ChannelOrder\n",
    "\n",
    "from model.TwinLite import TwinLiteNet\n",
    "from DataSet import CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntadmin/Desktop/TwinLiteNet/venv/lib/python3.11/site-packages/nobuco/trace/trace.py:366: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  outputs = orig_method(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TwinLiteNet(\n",
       "  (encoder): ESPNet_Encoder(\n",
       "    (level1): CBR(\n",
       "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=16)\n",
       "    )\n",
       "    (sample1): InputProjectionA(\n",
       "      (pool): ModuleList(\n",
       "        (0): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "      )\n",
       "    )\n",
       "    (sample2): InputProjectionA(\n",
       "      (pool): ModuleList(\n",
       "        (0-1): 2 x AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "      )\n",
       "    )\n",
       "    (b1): CBR(\n",
       "      (conv): Conv2d(19, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(19, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=19)\n",
       "    )\n",
       "    (level2_0): DownSamplerB(\n",
       "      (c1): C(\n",
       "        (conv): Conv2d(19, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (d1): CDilated(\n",
       "        (conv): Conv2d(12, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (d2): CDilated(\n",
       "        (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      )\n",
       "      (d4): CDilated(\n",
       "        (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      )\n",
       "      (d8): CDilated(\n",
       "        (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
       "      )\n",
       "      (d16): CDilated(\n",
       "        (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
       "      )\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=64)\n",
       "    )\n",
       "    (level2): ModuleList(\n",
       "      (0-1): 2 x DilatedParllelResidualBlockB(\n",
       "        (c1): C(\n",
       "          (conv): Conv2d(64, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (d1): CDilated(\n",
       "          (conv): Conv2d(12, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (d2): CDilated(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        )\n",
       "        (d4): CDilated(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        )\n",
       "        (d8): CDilated(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
       "        )\n",
       "        (d16): CDilated(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
       "        )\n",
       "        (bn): BR(\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (b2): CBR(\n",
       "      (conv): Conv2d(131, 131, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(131, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=131)\n",
       "    )\n",
       "    (level3_0): DownSamplerB(\n",
       "      (c1): C(\n",
       "        (conv): Conv2d(131, 25, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (d1): CDilated(\n",
       "        (conv): Conv2d(25, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (d2): CDilated(\n",
       "        (conv): Conv2d(25, 25, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      )\n",
       "      (d4): CDilated(\n",
       "        (conv): Conv2d(25, 25, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      )\n",
       "      (d8): CDilated(\n",
       "        (conv): Conv2d(25, 25, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
       "      )\n",
       "      (d16): CDilated(\n",
       "        (conv): Conv2d(25, 25, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
       "      )\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=128)\n",
       "    )\n",
       "    (level3): ModuleList(\n",
       "      (0-2): 3 x DilatedParllelResidualBlockB(\n",
       "        (c1): C(\n",
       "          (conv): Conv2d(128, 25, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (d1): CDilated(\n",
       "          (conv): Conv2d(25, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (d2): CDilated(\n",
       "          (conv): Conv2d(25, 25, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        )\n",
       "        (d4): CDilated(\n",
       "          (conv): Conv2d(25, 25, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        )\n",
       "        (d8): CDilated(\n",
       "          (conv): Conv2d(25, 25, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
       "        )\n",
       "        (d16): CDilated(\n",
       "          (conv): Conv2d(25, 25, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
       "        )\n",
       "        (bn): BR(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (b3): CBR(\n",
       "      (conv): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=32)\n",
       "    )\n",
       "    (sa): PAM_Module(\n",
       "      (query_conv): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (key_conv): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (value_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (sc): CAM_Module(\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (conv_sa): CBR(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=32)\n",
       "    )\n",
       "    (conv_sc): CBR(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=32)\n",
       "    )\n",
       "    (classifier): CBR(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=32)\n",
       "    )\n",
       "  )\n",
       "  (up_1_1): UPx2(\n",
       "    (deconv): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): PReLU(num_parameters=16)\n",
       "  )\n",
       "  (up_2_1): UPx2(\n",
       "    (deconv): ConvTranspose2d(16, 8, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): PReLU(num_parameters=8)\n",
       "  )\n",
       "  (up_1_2): UPx2(\n",
       "    (deconv): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): PReLU(num_parameters=16)\n",
       "  )\n",
       "  (up_2_2): UPx2(\n",
       "    (deconv): ConvTranspose2d(16, 8, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): PReLU(num_parameters=8)\n",
       "  )\n",
       "  (classifier_1): UPx2(\n",
       "    (deconv): ConvTranspose2d(8, 2, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(2, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): PReLU(num_parameters=2)\n",
       "  )\n",
       "  (classifier_2): UPx2(\n",
       "    (deconv): ConvTranspose2d(8, 2, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(2, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): PReLU(num_parameters=2)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load('pretrained/epo99_qat.pth', map_location='cpu')\n",
    "\n",
    "model = nn.Sequential(torch.ao.quantization.QuantStub(), TwinLiteNet(), torch.ao.quantization.DeQuantStub())\n",
    "model.load_state_dict(state_dict)\n",
    "model = model[1]\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO, CHANGE FOR YOUR OWN DATASET DIR\n",
    "DATASET_PATH = \"/media/ubuntadmin/67b3a250-6e0f-4a86-b15d-1b302250e0b4/home/ubuntadmin/Desktop/data/datasets/road-segmentation/TwinLiteTree/images\"\n",
    "MAX_CALIBRATION_IMG = 10\n",
    "dataset = CustomDataset(DATASET_PATH, valid=True)\n",
    "dataset.names = dataset.names[:MAX_CALIBRATION_IMG]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nobuco] Tracing (DONE): 216 ops [00:04]\n",
      "[Nobuco] Converting: |          | 2/162 ops [00:03]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 10:43:56.189338: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nobuco] Converting: |██████▌   | 107/162 ops [00:07]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 10:44:00.928166: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 51840000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nobuco] Converting: |███████   | 114/162 ops [00:08]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 10:44:01.892658: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 51840000 exceeds 10% of free system memory.\n",
      "2024-08-20 10:44:01.922141: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 51840000 exceeds 10% of free system memory.\n",
      "2024-08-20 10:44:01.951064: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 51840000 exceeds 10% of free system memory.\n",
      "2024-08-20 10:44:01.967234: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 51840000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nobuco] Converting (DONE): |██████████| 162/162 ops [00:13]\n",
      "Legend:\n",
      "    \u001b[32mGreen\u001b[0m — conversion successful\n",
      "    \u001b[33mYellow\u001b[0m — conversion imprecise\n",
      "    \u001b[31mRed\u001b[0m — conversion failed\n",
      "    \u001b[31m\u001b[7mRed\u001b[0m — no converter found\n",
      "    \u001b[0m\u001b[1mBold\u001b[0m — conversion applied directly\n",
      "    * — subgraph reused\n",
      "    \u001b[7mTensor\u001b[0m — this output is not dependent on any of subgraph's input tensors\n",
      "    \u001b[4mTensor\u001b[0m — this input is a parameter / constant\n",
      "    \u001b[90mTensor\u001b[0m — this tensor is useless\n",
      "\n",
      "\u001b[32mTwinLiteNet[model.TwinLite]\u001b[0m(float32_0<1,3,360,640>\u001b[0m) -> (float32_299<1,2,360,640>\u001b[0m, float32_326<1,2,360,640>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32mESPNet_Encoder[model.TwinLite]\u001b[0m(float32_0<1,3,360,640>\u001b[0m) -> float32_272<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCBR[model.TwinLite]\u001b[0m(float32_0<1,3,360,640>\u001b[0m) -> float32_9<1,16,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_0<1,3,360,640>\u001b[0m) -> float32_2<1,16,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_0<1,3,360,640>\u001b[0m, float32_1<16,3,3,3>\u001b[0m, None, (2, 2), (1, 1), (1, 1), 1) -> float32_2<1,16,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_2<1,16,180,320>\u001b[0m) -> float32_7<1,16,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_2<1,16,180,320>\u001b[0m, float32_3<16>\u001b[0m, float32_4<16>\u001b[0m, float32_5<16>\u001b[0m, float32_6<16>\u001b[0m, False, 0.1, 0.001) -> float32_7<1,16,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_2<1,16,180,320>\u001b[0m, float32_5<16>\u001b[0m, float32_6<16>\u001b[0m, float32_3<16>\u001b[0m, float32_4<16>\u001b[0m, False, 0.1, 0.001, True) -> float32_7<1,16,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mPReLU[torch.nn.modules.activation]\u001b[0m(float32_7<1,16,180,320>\u001b[0m) -> float32_9<1,16,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mprelu[torch.nn.functional]\u001b[0m(float32_7<1,16,180,320>\u001b[0m, float32_8<16>\u001b[0m) -> float32_9<1,16,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mInputProjectionA[model.TwinLite]\u001b[0m(float32_0<1,3,360,640>\u001b[0m) -> float32_10<1,3,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_0<1,3,360,640>\u001b[0m) -> float32_10<1,3,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mavg_pool2d[torch.nn.functional]\u001b[0m(float32_0<1,3,360,640>\u001b[0m, 3, 2, 1, False, True, None) -> float32_10<1,3,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mInputProjectionA[model.TwinLite]\u001b[0m(float32_0<1,3,360,640>\u001b[0m) -> float32_12<1,3,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_0<1,3,360,640>\u001b[0m) -> float32_11<1,3,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mavg_pool2d[torch.nn.functional]\u001b[0m(float32_0<1,3,360,640>\u001b[0m, 3, 2, 1, False, True, None) -> float32_11<1,3,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_11<1,3,180,320>\u001b[0m) -> float32_12<1,3,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mavg_pool2d[torch.nn.functional]\u001b[0m(float32_11<1,3,180,320>\u001b[0m, 3, 2, 1, False, True, None) -> float32_12<1,3,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_9<1,16,180,320>\u001b[0m, float32_10<1,3,180,320>\u001b[0m], 1) -> float32_13<1,19,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCBR[model.TwinLite]\u001b[0m(float32_13<1,19,180,320>\u001b[0m) -> float32_22<1,19,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_13<1,19,180,320>\u001b[0m) -> float32_15<1,19,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_13<1,19,180,320>\u001b[0m, float32_14<19,19,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_15<1,19,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_15<1,19,180,320>\u001b[0m) -> float32_20<1,19,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_15<1,19,180,320>\u001b[0m, float32_16<19>\u001b[0m, float32_17<19>\u001b[0m, float32_18<19>\u001b[0m, float32_19<19>\u001b[0m, False, 0.1, 0.001) -> float32_20<1,19,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_15<1,19,180,320>\u001b[0m, float32_18<19>\u001b[0m, float32_19<19>\u001b[0m, float32_16<19>\u001b[0m, float32_17<19>\u001b[0m, False, 0.1, 0.001, True) -> float32_20<1,19,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mPReLU[torch.nn.modules.activation]\u001b[0m(float32_20<1,19,180,320>\u001b[0m) -> float32_22<1,19,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mprelu[torch.nn.functional]\u001b[0m(float32_20<1,19,180,320>\u001b[0m, float32_21<19>\u001b[0m) -> float32_22<1,19,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mDownSamplerB[model.TwinLite]\u001b[0m(float32_22<1,19,180,320>\u001b[0m) -> float32_45<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mC[model.TwinLite]\u001b[0m(float32_22<1,19,180,320>\u001b[0m) -> float32_24<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_22<1,19,180,320>\u001b[0m) -> float32_24<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_22<1,19,180,320>\u001b[0m, float32_23<12,19,3,3>\u001b[0m, None, (2, 2), (1, 1), (1, 1), 1) -> float32_24<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_24<1,12,90,160>\u001b[0m) -> float32_26<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_24<1,12,90,160>\u001b[0m) -> float32_26<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_24<1,12,90,160>\u001b[0m, float32_25<16,12,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_26<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_24<1,12,90,160>\u001b[0m) -> float32_28<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_24<1,12,90,160>\u001b[0m) -> float32_28<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_24<1,12,90,160>\u001b[0m, float32_27<12,12,3,3>\u001b[0m, None, (1, 1), (2, 2), (2, 2), 1) -> float32_28<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_24<1,12,90,160>\u001b[0m) -> float32_30<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_24<1,12,90,160>\u001b[0m) -> float32_30<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_24<1,12,90,160>\u001b[0m, float32_29<12,12,3,3>\u001b[0m, None, (1, 1), (4, 4), (4, 4), 1) -> float32_30<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_24<1,12,90,160>\u001b[0m) -> float32_32<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_24<1,12,90,160>\u001b[0m) -> float32_32<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_24<1,12,90,160>\u001b[0m, float32_31<12,12,3,3>\u001b[0m, None, (1, 1), (8, 8), (8, 8), 1) -> float32_32<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_24<1,12,90,160>\u001b[0m) -> float32_34<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_24<1,12,90,160>\u001b[0m) -> float32_34<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_24<1,12,90,160>\u001b[0m, float32_33<12,12,3,3>\u001b[0m, None, (1, 1), (16, 16), (16, 16), 1) -> float32_34<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_28<1,12,90,160>\u001b[0m, float32_30<1,12,90,160>\u001b[0m) -> float32_35<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_28<1,12,90,160>\u001b[0m, float32_30<1,12,90,160>\u001b[0m) -> float32_35<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_35<1,12,90,160>\u001b[0m, float32_32<1,12,90,160>\u001b[0m) -> float32_36<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_35<1,12,90,160>\u001b[0m, float32_32<1,12,90,160>\u001b[0m) -> float32_36<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_36<1,12,90,160>\u001b[0m, float32_34<1,12,90,160>\u001b[0m) -> float32_37<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_36<1,12,90,160>\u001b[0m, float32_34<1,12,90,160>\u001b[0m) -> float32_37<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_26<1,16,90,160>\u001b[0m, float32_28<1,12,90,160>\u001b[0m, float32_35<1,12,90,160>\u001b[0m, float32_36<1,12,90,160>\u001b[0m, float32_37<1,12,90,160>\u001b[0m], 1) -> float32_38<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_38<1,64,90,160>\u001b[0m) -> float32_43<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_38<1,64,90,160>\u001b[0m, float32_39<64>\u001b[0m, float32_40<64>\u001b[0m, float32_41<64>\u001b[0m, float32_42<64>\u001b[0m, False, 0.1, 0.001) -> float32_43<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_38<1,64,90,160>\u001b[0m, float32_41<64>\u001b[0m, float32_42<64>\u001b[0m, float32_39<64>\u001b[0m, float32_40<64>\u001b[0m, False, 0.1, 0.001, True) -> float32_43<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mPReLU[torch.nn.modules.activation]\u001b[0m(float32_43<1,64,90,160>\u001b[0m) -> float32_45<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mprelu[torch.nn.functional]\u001b[0m(float32_43<1,64,90,160>\u001b[0m, float32_44<64>\u001b[0m) -> float32_45<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mDilatedParllelResidualBlockB[model.TwinLite]\u001b[0m(float32_45<1,64,90,160>\u001b[0m) -> float32_69<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mC[model.TwinLite]\u001b[0m(float32_45<1,64,90,160>\u001b[0m) -> float32_47<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_45<1,64,90,160>\u001b[0m) -> float32_47<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_45<1,64,90,160>\u001b[0m, float32_46<12,64,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_47<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_47<1,12,90,160>\u001b[0m) -> float32_49<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_47<1,12,90,160>\u001b[0m) -> float32_49<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_47<1,12,90,160>\u001b[0m, float32_48<16,12,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_49<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_47<1,12,90,160>\u001b[0m) -> float32_51<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_47<1,12,90,160>\u001b[0m) -> float32_51<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_47<1,12,90,160>\u001b[0m, float32_50<12,12,3,3>\u001b[0m, None, (1, 1), (2, 2), (2, 2), 1) -> float32_51<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_47<1,12,90,160>\u001b[0m) -> float32_53<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_47<1,12,90,160>\u001b[0m) -> float32_53<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_47<1,12,90,160>\u001b[0m, float32_52<12,12,3,3>\u001b[0m, None, (1, 1), (4, 4), (4, 4), 1) -> float32_53<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_47<1,12,90,160>\u001b[0m) -> float32_55<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_47<1,12,90,160>\u001b[0m) -> float32_55<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_47<1,12,90,160>\u001b[0m, float32_54<12,12,3,3>\u001b[0m, None, (1, 1), (8, 8), (8, 8), 1) -> float32_55<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_47<1,12,90,160>\u001b[0m) -> float32_57<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_47<1,12,90,160>\u001b[0m) -> float32_57<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_47<1,12,90,160>\u001b[0m, float32_56<12,12,3,3>\u001b[0m, None, (1, 1), (16, 16), (16, 16), 1) -> float32_57<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_51<1,12,90,160>\u001b[0m, float32_53<1,12,90,160>\u001b[0m) -> float32_58<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_51<1,12,90,160>\u001b[0m, float32_53<1,12,90,160>\u001b[0m) -> float32_58<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_58<1,12,90,160>\u001b[0m, float32_55<1,12,90,160>\u001b[0m) -> float32_59<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_58<1,12,90,160>\u001b[0m, float32_55<1,12,90,160>\u001b[0m) -> float32_59<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_59<1,12,90,160>\u001b[0m, float32_57<1,12,90,160>\u001b[0m) -> float32_60<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_59<1,12,90,160>\u001b[0m, float32_57<1,12,90,160>\u001b[0m) -> float32_60<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_49<1,16,90,160>\u001b[0m, float32_51<1,12,90,160>\u001b[0m, float32_58<1,12,90,160>\u001b[0m, float32_59<1,12,90,160>\u001b[0m, float32_60<1,12,90,160>\u001b[0m], 1) -> float32_61<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_45<1,64,90,160>\u001b[0m, float32_61<1,64,90,160>\u001b[0m) -> float32_62<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_45<1,64,90,160>\u001b[0m, float32_61<1,64,90,160>\u001b[0m) -> float32_62<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mBR[model.TwinLite]\u001b[0m(float32_62<1,64,90,160>\u001b[0m) -> float32_69<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_62<1,64,90,160>\u001b[0m) -> float32_67<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_62<1,64,90,160>\u001b[0m, float32_63<64>\u001b[0m, float32_64<64>\u001b[0m, float32_65<64>\u001b[0m, float32_66<64>\u001b[0m, False, 0.1, 0.001) -> float32_67<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_62<1,64,90,160>\u001b[0m, float32_65<64>\u001b[0m, float32_66<64>\u001b[0m, float32_63<64>\u001b[0m, float32_64<64>\u001b[0m, False, 0.1, 0.001, True) -> float32_67<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mPReLU[torch.nn.modules.activation]\u001b[0m(float32_67<1,64,90,160>\u001b[0m) -> float32_69<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mprelu[torch.nn.functional]\u001b[0m(float32_67<1,64,90,160>\u001b[0m, float32_68<64>\u001b[0m) -> float32_69<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mDilatedParllelResidualBlockB[model.TwinLite]\u001b[0m(float32_69<1,64,90,160>\u001b[0m) -> float32_93<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mC[model.TwinLite]\u001b[0m(float32_69<1,64,90,160>\u001b[0m) -> float32_71<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_69<1,64,90,160>\u001b[0m) -> float32_71<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_69<1,64,90,160>\u001b[0m, float32_70<12,64,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_71<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_71<1,12,90,160>\u001b[0m) -> float32_73<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_71<1,12,90,160>\u001b[0m) -> float32_73<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_71<1,12,90,160>\u001b[0m, float32_72<16,12,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_73<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_71<1,12,90,160>\u001b[0m) -> float32_75<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_71<1,12,90,160>\u001b[0m) -> float32_75<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_71<1,12,90,160>\u001b[0m, float32_74<12,12,3,3>\u001b[0m, None, (1, 1), (2, 2), (2, 2), 1) -> float32_75<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_71<1,12,90,160>\u001b[0m) -> float32_77<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_71<1,12,90,160>\u001b[0m) -> float32_77<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_71<1,12,90,160>\u001b[0m, float32_76<12,12,3,3>\u001b[0m, None, (1, 1), (4, 4), (4, 4), 1) -> float32_77<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_71<1,12,90,160>\u001b[0m) -> float32_79<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_71<1,12,90,160>\u001b[0m) -> float32_79<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_71<1,12,90,160>\u001b[0m, float32_78<12,12,3,3>\u001b[0m, None, (1, 1), (8, 8), (8, 8), 1) -> float32_79<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_71<1,12,90,160>\u001b[0m) -> float32_81<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_71<1,12,90,160>\u001b[0m) -> float32_81<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_71<1,12,90,160>\u001b[0m, float32_80<12,12,3,3>\u001b[0m, None, (1, 1), (16, 16), (16, 16), 1) -> float32_81<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_75<1,12,90,160>\u001b[0m, float32_77<1,12,90,160>\u001b[0m) -> float32_82<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_75<1,12,90,160>\u001b[0m, float32_77<1,12,90,160>\u001b[0m) -> float32_82<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_82<1,12,90,160>\u001b[0m, float32_79<1,12,90,160>\u001b[0m) -> float32_83<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_82<1,12,90,160>\u001b[0m, float32_79<1,12,90,160>\u001b[0m) -> float32_83<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_83<1,12,90,160>\u001b[0m, float32_81<1,12,90,160>\u001b[0m) -> float32_84<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_83<1,12,90,160>\u001b[0m, float32_81<1,12,90,160>\u001b[0m) -> float32_84<1,12,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_73<1,16,90,160>\u001b[0m, float32_75<1,12,90,160>\u001b[0m, float32_82<1,12,90,160>\u001b[0m, float32_83<1,12,90,160>\u001b[0m, float32_84<1,12,90,160>\u001b[0m], 1) -> float32_85<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_69<1,64,90,160>\u001b[0m, float32_85<1,64,90,160>\u001b[0m) -> float32_86<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_69<1,64,90,160>\u001b[0m, float32_85<1,64,90,160>\u001b[0m) -> float32_86<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mBR[model.TwinLite]\u001b[0m(float32_86<1,64,90,160>\u001b[0m) -> float32_93<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_86<1,64,90,160>\u001b[0m) -> float32_91<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_86<1,64,90,160>\u001b[0m, float32_87<64>\u001b[0m, float32_88<64>\u001b[0m, float32_89<64>\u001b[0m, float32_90<64>\u001b[0m, False, 0.1, 0.001) -> float32_91<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_86<1,64,90,160>\u001b[0m, float32_89<64>\u001b[0m, float32_90<64>\u001b[0m, float32_87<64>\u001b[0m, float32_88<64>\u001b[0m, False, 0.1, 0.001, True) -> float32_91<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mPReLU[torch.nn.modules.activation]\u001b[0m(float32_91<1,64,90,160>\u001b[0m) -> float32_93<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mprelu[torch.nn.functional]\u001b[0m(float32_91<1,64,90,160>\u001b[0m, float32_92<64>\u001b[0m) -> float32_93<1,64,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_93<1,64,90,160>\u001b[0m, float32_45<1,64,90,160>\u001b[0m, float32_12<1,3,90,160>\u001b[0m], 1) -> float32_94<1,131,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCBR[model.TwinLite]\u001b[0m(float32_94<1,131,90,160>\u001b[0m) -> float32_103<1,131,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_94<1,131,90,160>\u001b[0m) -> float32_96<1,131,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_94<1,131,90,160>\u001b[0m, float32_95<131,131,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_96<1,131,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_96<1,131,90,160>\u001b[0m) -> float32_101<1,131,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_96<1,131,90,160>\u001b[0m, float32_97<131>\u001b[0m, float32_98<131>\u001b[0m, float32_99<131>\u001b[0m, float32_100<131>\u001b[0m, False, 0.1, 0.001) -> float32_101<1,131,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_96<1,131,90,160>\u001b[0m, float32_99<131>\u001b[0m, float32_100<131>\u001b[0m, float32_97<131>\u001b[0m, float32_98<131>\u001b[0m, False, 0.1, 0.001, True) -> float32_101<1,131,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mPReLU[torch.nn.modules.activation]\u001b[0m(float32_101<1,131,90,160>\u001b[0m) -> float32_103<1,131,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mprelu[torch.nn.functional]\u001b[0m(float32_101<1,131,90,160>\u001b[0m, float32_102<131>\u001b[0m) -> float32_103<1,131,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mDownSamplerB[model.TwinLite]\u001b[0m(float32_103<1,131,90,160>\u001b[0m) -> float32_126<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mC[model.TwinLite]\u001b[0m(float32_103<1,131,90,160>\u001b[0m) -> float32_105<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_103<1,131,90,160>\u001b[0m) -> float32_105<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_103<1,131,90,160>\u001b[0m, float32_104<25,131,3,3>\u001b[0m, None, (2, 2), (1, 1), (1, 1), 1) -> float32_105<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_105<1,25,45,80>\u001b[0m) -> float32_107<1,28,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_105<1,25,45,80>\u001b[0m) -> float32_107<1,28,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_105<1,25,45,80>\u001b[0m, float32_106<28,25,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_107<1,28,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_105<1,25,45,80>\u001b[0m) -> float32_109<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_105<1,25,45,80>\u001b[0m) -> float32_109<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_105<1,25,45,80>\u001b[0m, float32_108<25,25,3,3>\u001b[0m, None, (1, 1), (2, 2), (2, 2), 1) -> float32_109<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_105<1,25,45,80>\u001b[0m) -> float32_111<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_105<1,25,45,80>\u001b[0m) -> float32_111<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_105<1,25,45,80>\u001b[0m, float32_110<25,25,3,3>\u001b[0m, None, (1, 1), (4, 4), (4, 4), 1) -> float32_111<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_105<1,25,45,80>\u001b[0m) -> float32_113<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_105<1,25,45,80>\u001b[0m) -> float32_113<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_105<1,25,45,80>\u001b[0m, float32_112<25,25,3,3>\u001b[0m, None, (1, 1), (8, 8), (8, 8), 1) -> float32_113<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_105<1,25,45,80>\u001b[0m) -> float32_115<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_105<1,25,45,80>\u001b[0m) -> float32_115<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_105<1,25,45,80>\u001b[0m, float32_114<25,25,3,3>\u001b[0m, None, (1, 1), (16, 16), (16, 16), 1) -> float32_115<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_109<1,25,45,80>\u001b[0m, float32_111<1,25,45,80>\u001b[0m) -> float32_116<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_109<1,25,45,80>\u001b[0m, float32_111<1,25,45,80>\u001b[0m) -> float32_116<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_116<1,25,45,80>\u001b[0m, float32_113<1,25,45,80>\u001b[0m) -> float32_117<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_116<1,25,45,80>\u001b[0m, float32_113<1,25,45,80>\u001b[0m) -> float32_117<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_117<1,25,45,80>\u001b[0m, float32_115<1,25,45,80>\u001b[0m) -> float32_118<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_117<1,25,45,80>\u001b[0m, float32_115<1,25,45,80>\u001b[0m) -> float32_118<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_107<1,28,45,80>\u001b[0m, float32_109<1,25,45,80>\u001b[0m, float32_116<1,25,45,80>\u001b[0m, float32_117<1,25,45,80>\u001b[0m, float32_118<1,25,45,80>\u001b[0m], 1) -> float32_119<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_119<1,128,45,80>\u001b[0m) -> float32_124<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_119<1,128,45,80>\u001b[0m, float32_120<128>\u001b[0m, float32_121<128>\u001b[0m, float32_122<128>\u001b[0m, float32_123<128>\u001b[0m, False, 0.1, 0.001) -> float32_124<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_119<1,128,45,80>\u001b[0m, float32_122<128>\u001b[0m, float32_123<128>\u001b[0m, float32_120<128>\u001b[0m, float32_121<128>\u001b[0m, False, 0.1, 0.001, True) -> float32_124<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mPReLU[torch.nn.modules.activation]\u001b[0m(float32_124<1,128,45,80>\u001b[0m) -> float32_126<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mprelu[torch.nn.functional]\u001b[0m(float32_124<1,128,45,80>\u001b[0m, float32_125<128>\u001b[0m) -> float32_126<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mDilatedParllelResidualBlockB[model.TwinLite]\u001b[0m(float32_126<1,128,45,80>\u001b[0m) -> float32_150<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mC[model.TwinLite]\u001b[0m(float32_126<1,128,45,80>\u001b[0m) -> float32_128<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_126<1,128,45,80>\u001b[0m) -> float32_128<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_126<1,128,45,80>\u001b[0m, float32_127<25,128,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_128<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_128<1,25,45,80>\u001b[0m) -> float32_130<1,28,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_128<1,25,45,80>\u001b[0m) -> float32_130<1,28,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_128<1,25,45,80>\u001b[0m, float32_129<28,25,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_130<1,28,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_128<1,25,45,80>\u001b[0m) -> float32_132<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_128<1,25,45,80>\u001b[0m) -> float32_132<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_128<1,25,45,80>\u001b[0m, float32_131<25,25,3,3>\u001b[0m, None, (1, 1), (2, 2), (2, 2), 1) -> float32_132<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_128<1,25,45,80>\u001b[0m) -> float32_134<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_128<1,25,45,80>\u001b[0m) -> float32_134<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_128<1,25,45,80>\u001b[0m, float32_133<25,25,3,3>\u001b[0m, None, (1, 1), (4, 4), (4, 4), 1) -> float32_134<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_128<1,25,45,80>\u001b[0m) -> float32_136<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_128<1,25,45,80>\u001b[0m) -> float32_136<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_128<1,25,45,80>\u001b[0m, float32_135<25,25,3,3>\u001b[0m, None, (1, 1), (8, 8), (8, 8), 1) -> float32_136<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_128<1,25,45,80>\u001b[0m) -> float32_138<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_128<1,25,45,80>\u001b[0m) -> float32_138<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_128<1,25,45,80>\u001b[0m, float32_137<25,25,3,3>\u001b[0m, None, (1, 1), (16, 16), (16, 16), 1) -> float32_138<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_132<1,25,45,80>\u001b[0m, float32_134<1,25,45,80>\u001b[0m) -> float32_139<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_132<1,25,45,80>\u001b[0m, float32_134<1,25,45,80>\u001b[0m) -> float32_139<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_139<1,25,45,80>\u001b[0m, float32_136<1,25,45,80>\u001b[0m) -> float32_140<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_139<1,25,45,80>\u001b[0m, float32_136<1,25,45,80>\u001b[0m) -> float32_140<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_140<1,25,45,80>\u001b[0m, float32_138<1,25,45,80>\u001b[0m) -> float32_141<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_140<1,25,45,80>\u001b[0m, float32_138<1,25,45,80>\u001b[0m) -> float32_141<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_130<1,28,45,80>\u001b[0m, float32_132<1,25,45,80>\u001b[0m, float32_139<1,25,45,80>\u001b[0m, float32_140<1,25,45,80>\u001b[0m, float32_141<1,25,45,80>\u001b[0m], 1) -> float32_142<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_126<1,128,45,80>\u001b[0m, float32_142<1,128,45,80>\u001b[0m) -> float32_143<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_126<1,128,45,80>\u001b[0m, float32_142<1,128,45,80>\u001b[0m) -> float32_143<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mBR[model.TwinLite]\u001b[0m(float32_143<1,128,45,80>\u001b[0m) -> float32_150<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_143<1,128,45,80>\u001b[0m) -> float32_148<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_143<1,128,45,80>\u001b[0m, float32_144<128>\u001b[0m, float32_145<128>\u001b[0m, float32_146<128>\u001b[0m, float32_147<128>\u001b[0m, False, 0.1, 0.001) -> float32_148<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_143<1,128,45,80>\u001b[0m, float32_146<128>\u001b[0m, float32_147<128>\u001b[0m, float32_144<128>\u001b[0m, float32_145<128>\u001b[0m, False, 0.1, 0.001, True) -> float32_148<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mPReLU[torch.nn.modules.activation]\u001b[0m(float32_148<1,128,45,80>\u001b[0m) -> float32_150<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mprelu[torch.nn.functional]\u001b[0m(float32_148<1,128,45,80>\u001b[0m, float32_149<128>\u001b[0m) -> float32_150<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mDilatedParllelResidualBlockB[model.TwinLite]\u001b[0m(float32_150<1,128,45,80>\u001b[0m) -> float32_174<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mC[model.TwinLite]\u001b[0m(float32_150<1,128,45,80>\u001b[0m) -> float32_152<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_150<1,128,45,80>\u001b[0m) -> float32_152<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_150<1,128,45,80>\u001b[0m, float32_151<25,128,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_152<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_152<1,25,45,80>\u001b[0m) -> float32_154<1,28,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_152<1,25,45,80>\u001b[0m) -> float32_154<1,28,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_152<1,25,45,80>\u001b[0m, float32_153<28,25,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_154<1,28,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_152<1,25,45,80>\u001b[0m) -> float32_156<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_152<1,25,45,80>\u001b[0m) -> float32_156<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_152<1,25,45,80>\u001b[0m, float32_155<25,25,3,3>\u001b[0m, None, (1, 1), (2, 2), (2, 2), 1) -> float32_156<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_152<1,25,45,80>\u001b[0m) -> float32_158<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_152<1,25,45,80>\u001b[0m) -> float32_158<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_152<1,25,45,80>\u001b[0m, float32_157<25,25,3,3>\u001b[0m, None, (1, 1), (4, 4), (4, 4), 1) -> float32_158<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_152<1,25,45,80>\u001b[0m) -> float32_160<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_152<1,25,45,80>\u001b[0m) -> float32_160<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_152<1,25,45,80>\u001b[0m, float32_159<25,25,3,3>\u001b[0m, None, (1, 1), (8, 8), (8, 8), 1) -> float32_160<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_152<1,25,45,80>\u001b[0m) -> float32_162<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_152<1,25,45,80>\u001b[0m) -> float32_162<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_152<1,25,45,80>\u001b[0m, float32_161<25,25,3,3>\u001b[0m, None, (1, 1), (16, 16), (16, 16), 1) -> float32_162<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_156<1,25,45,80>\u001b[0m, float32_158<1,25,45,80>\u001b[0m) -> float32_163<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_156<1,25,45,80>\u001b[0m, float32_158<1,25,45,80>\u001b[0m) -> float32_163<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_163<1,25,45,80>\u001b[0m, float32_160<1,25,45,80>\u001b[0m) -> float32_164<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_163<1,25,45,80>\u001b[0m, float32_160<1,25,45,80>\u001b[0m) -> float32_164<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_164<1,25,45,80>\u001b[0m, float32_162<1,25,45,80>\u001b[0m) -> float32_165<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_164<1,25,45,80>\u001b[0m, float32_162<1,25,45,80>\u001b[0m) -> float32_165<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_154<1,28,45,80>\u001b[0m, float32_156<1,25,45,80>\u001b[0m, float32_163<1,25,45,80>\u001b[0m, float32_164<1,25,45,80>\u001b[0m, float32_165<1,25,45,80>\u001b[0m], 1) -> float32_166<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_150<1,128,45,80>\u001b[0m, float32_166<1,128,45,80>\u001b[0m) -> float32_167<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_150<1,128,45,80>\u001b[0m, float32_166<1,128,45,80>\u001b[0m) -> float32_167<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mBR[model.TwinLite]\u001b[0m(float32_167<1,128,45,80>\u001b[0m) -> float32_174<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_167<1,128,45,80>\u001b[0m) -> float32_172<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_167<1,128,45,80>\u001b[0m, float32_168<128>\u001b[0m, float32_169<128>\u001b[0m, float32_170<128>\u001b[0m, float32_171<128>\u001b[0m, False, 0.1, 0.001) -> float32_172<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_167<1,128,45,80>\u001b[0m, float32_170<128>\u001b[0m, float32_171<128>\u001b[0m, float32_168<128>\u001b[0m, float32_169<128>\u001b[0m, False, 0.1, 0.001, True) -> float32_172<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mPReLU[torch.nn.modules.activation]\u001b[0m(float32_172<1,128,45,80>\u001b[0m) -> float32_174<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mprelu[torch.nn.functional]\u001b[0m(float32_172<1,128,45,80>\u001b[0m, float32_173<128>\u001b[0m) -> float32_174<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mDilatedParllelResidualBlockB[model.TwinLite]\u001b[0m(float32_174<1,128,45,80>\u001b[0m) -> float32_198<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mC[model.TwinLite]\u001b[0m(float32_174<1,128,45,80>\u001b[0m) -> float32_176<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_174<1,128,45,80>\u001b[0m) -> float32_176<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_174<1,128,45,80>\u001b[0m, float32_175<25,128,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_176<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_176<1,25,45,80>\u001b[0m) -> float32_178<1,28,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_176<1,25,45,80>\u001b[0m) -> float32_178<1,28,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_176<1,25,45,80>\u001b[0m, float32_177<28,25,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_178<1,28,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_176<1,25,45,80>\u001b[0m) -> float32_180<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_176<1,25,45,80>\u001b[0m) -> float32_180<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_176<1,25,45,80>\u001b[0m, float32_179<25,25,3,3>\u001b[0m, None, (1, 1), (2, 2), (2, 2), 1) -> float32_180<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_176<1,25,45,80>\u001b[0m) -> float32_182<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_176<1,25,45,80>\u001b[0m) -> float32_182<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_176<1,25,45,80>\u001b[0m, float32_181<25,25,3,3>\u001b[0m, None, (1, 1), (4, 4), (4, 4), 1) -> float32_182<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_176<1,25,45,80>\u001b[0m) -> float32_184<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_176<1,25,45,80>\u001b[0m) -> float32_184<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_176<1,25,45,80>\u001b[0m, float32_183<25,25,3,3>\u001b[0m, None, (1, 1), (8, 8), (8, 8), 1) -> float32_184<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLite]\u001b[0m(float32_176<1,25,45,80>\u001b[0m) -> float32_186<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_176<1,25,45,80>\u001b[0m) -> float32_186<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_176<1,25,45,80>\u001b[0m, float32_185<25,25,3,3>\u001b[0m, None, (1, 1), (16, 16), (16, 16), 1) -> float32_186<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_180<1,25,45,80>\u001b[0m, float32_182<1,25,45,80>\u001b[0m) -> float32_187<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_180<1,25,45,80>\u001b[0m, float32_182<1,25,45,80>\u001b[0m) -> float32_187<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_187<1,25,45,80>\u001b[0m, float32_184<1,25,45,80>\u001b[0m) -> float32_188<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_187<1,25,45,80>\u001b[0m, float32_184<1,25,45,80>\u001b[0m) -> float32_188<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_188<1,25,45,80>\u001b[0m, float32_186<1,25,45,80>\u001b[0m) -> float32_189<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_188<1,25,45,80>\u001b[0m, float32_186<1,25,45,80>\u001b[0m) -> float32_189<1,25,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_178<1,28,45,80>\u001b[0m, float32_180<1,25,45,80>\u001b[0m, float32_187<1,25,45,80>\u001b[0m, float32_188<1,25,45,80>\u001b[0m, float32_189<1,25,45,80>\u001b[0m], 1) -> float32_190<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_174<1,128,45,80>\u001b[0m, float32_190<1,128,45,80>\u001b[0m) -> float32_191<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_174<1,128,45,80>\u001b[0m, float32_190<1,128,45,80>\u001b[0m) -> float32_191<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mBR[model.TwinLite]\u001b[0m(float32_191<1,128,45,80>\u001b[0m) -> float32_198<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_191<1,128,45,80>\u001b[0m) -> float32_196<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_191<1,128,45,80>\u001b[0m, float32_192<128>\u001b[0m, float32_193<128>\u001b[0m, float32_194<128>\u001b[0m, float32_195<128>\u001b[0m, False, 0.1, 0.001) -> float32_196<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_191<1,128,45,80>\u001b[0m, float32_194<128>\u001b[0m, float32_195<128>\u001b[0m, float32_192<128>\u001b[0m, float32_193<128>\u001b[0m, False, 0.1, 0.001, True) -> float32_196<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mPReLU[torch.nn.modules.activation]\u001b[0m(float32_196<1,128,45,80>\u001b[0m) -> float32_198<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mprelu[torch.nn.functional]\u001b[0m(float32_196<1,128,45,80>\u001b[0m, float32_197<128>\u001b[0m) -> float32_198<1,128,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_126<1,128,45,80>\u001b[0m, float32_198<1,128,45,80>\u001b[0m], 1) -> float32_199<1,256,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCBR[model.TwinLite]\u001b[0m(float32_199<1,256,45,80>\u001b[0m) -> float32_208<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_199<1,256,45,80>\u001b[0m) -> float32_201<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_199<1,256,45,80>\u001b[0m, float32_200<32,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_201<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_201<1,32,45,80>\u001b[0m) -> float32_206<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_201<1,32,45,80>\u001b[0m, float32_202<32>\u001b[0m, float32_203<32>\u001b[0m, float32_204<32>\u001b[0m, float32_205<32>\u001b[0m, False, 0.1, 0.001) -> float32_206<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_201<1,32,45,80>\u001b[0m, float32_204<32>\u001b[0m, float32_205<32>\u001b[0m, float32_202<32>\u001b[0m, float32_203<32>\u001b[0m, False, 0.1, 0.001, True) -> float32_206<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mPReLU[torch.nn.modules.activation]\u001b[0m(float32_206<1,32,45,80>\u001b[0m) -> float32_208<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mprelu[torch.nn.functional]\u001b[0m(float32_206<1,32,45,80>\u001b[0m, float32_207<32>\u001b[0m) -> float32_208<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mPAM_Module[model.TwinLite]\u001b[0m(float32_208<1,32,45,80>\u001b[0m) -> float32_229<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_208<1,32,45,80>\u001b[0m) -> float32_211<1,4,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_208<1,32,45,80>\u001b[0m, float32_209<4,32,1,1>\u001b[0m, float32_210<4>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_211<1,4,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_211<1,4,45,80>\u001b[0m, 1, -1, 3600) -> float32_212<1,4,3600>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_212<1,4,3600>\u001b[0m, 0, 2, 1) -> float32_213<1,3600,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_208<1,32,45,80>\u001b[0m) -> float32_216<1,4,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_208<1,32,45,80>\u001b[0m, float32_214<4,32,1,1>\u001b[0m, float32_215<4>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_216<1,4,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_216<1,4,45,80>\u001b[0m, 1, -1, 3600) -> float32_217<1,4,3600>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mbmm[torch]\u001b[0m(float32_213<1,3600,4>\u001b[0m, float32_217<1,4,3600>\u001b[0m) -> float32_218<1,3600,3600>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSoftmax[torch.nn.modules.activation]\u001b[0m(float32_218<1,3600,3600>\u001b[0m) -> float32_219<1,3600,3600>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1msoftmax[torch.nn.functional]\u001b[0m(float32_218<1,3600,3600>\u001b[0m, -1, _stacklevel=5) -> float32_219<1,3600,3600>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0msoftmax[torch.Tensor]\u001b[0m(float32_218<1,3600,3600>\u001b[0m, -1) -> float32_219<1,3600,3600>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_208<1,32,45,80>\u001b[0m) -> float32_222<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_208<1,32,45,80>\u001b[0m, float32_220<32,32,1,1>\u001b[0m, float32_221<32>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_222<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_222<1,32,45,80>\u001b[0m, 1, -1, 3600) -> float32_223<1,32,3600>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_219<1,3600,3600>\u001b[0m, 0, 2, 1) -> float32_224<1,3600,3600>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mbmm[torch]\u001b[0m(float32_223<1,32,3600>\u001b[0m, float32_224<1,3600,3600>\u001b[0m) -> float32_225<1,32,3600>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_225<1,32,3600>\u001b[0m, 1, 32, 45, 80) -> float32_226<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(\u001b[4mfloat32_227<1>\u001b[0m, float32_226<1,32,45,80>\u001b[0m) -> float32_228<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_227<1>\u001b[0m, float32_226<1,32,45,80>\u001b[0m) -> float32_228<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_228<1,32,45,80>\u001b[0m, float32_208<1,32,45,80>\u001b[0m) -> float32_229<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_228<1,32,45,80>\u001b[0m, float32_208<1,32,45,80>\u001b[0m) -> float32_229<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCBR[model.TwinLite]\u001b[0m(float32_229<1,32,45,80>\u001b[0m) -> float32_238<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_229<1,32,45,80>\u001b[0m) -> float32_231<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_229<1,32,45,80>\u001b[0m, float32_230<32,32,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_231<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_231<1,32,45,80>\u001b[0m) -> float32_236<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_231<1,32,45,80>\u001b[0m, float32_232<32>\u001b[0m, float32_233<32>\u001b[0m, float32_234<32>\u001b[0m, float32_235<32>\u001b[0m, False, 0.1, 0.001) -> float32_236<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_231<1,32,45,80>\u001b[0m, float32_234<32>\u001b[0m, float32_235<32>\u001b[0m, float32_232<32>\u001b[0m, float32_233<32>\u001b[0m, False, 0.1, 0.001, True) -> float32_236<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mPReLU[torch.nn.modules.activation]\u001b[0m(float32_236<1,32,45,80>\u001b[0m) -> float32_238<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mprelu[torch.nn.functional]\u001b[0m(float32_236<1,32,45,80>\u001b[0m, float32_237<32>\u001b[0m) -> float32_238<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCAM_Module[model.TwinLite]\u001b[0m(float32_208<1,32,45,80>\u001b[0m) -> float32_253<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_208<1,32,45,80>\u001b[0m, 1, 32, -1) -> float32_239<1,32,3600>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_208<1,32,45,80>\u001b[0m, 1, 32, -1) -> float32_240<1,32,3600>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_240<1,32,3600>\u001b[0m, 0, 2, 1) -> float32_241<1,3600,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mbmm[torch]\u001b[0m(float32_239<1,32,3600>\u001b[0m, float32_241<1,3600,32>\u001b[0m) -> float32_242<1,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mmax[torch]\u001b[0m(float32_242<1,32,32>\u001b[0m, -1, keepdim=True) -> (float32_243<1,32,1>\u001b[0m, \u001b[90mint64_244<1,32,1>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mexpand_as[torch.Tensor]\u001b[0m(float32_243<1,32,1>\u001b[0m, float32_242<1,32,32>\u001b[0m) -> float32_245<1,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__sub__[torch.Tensor]\u001b[0m(float32_245<1,32,32>\u001b[0m, float32_242<1,32,32>\u001b[0m) -> float32_246<1,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0msub[TensorBase]\u001b[0m(float32_245<1,32,32>\u001b[0m, float32_242<1,32,32>\u001b[0m) -> float32_246<1,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSoftmax[torch.nn.modules.activation]\u001b[0m(float32_246<1,32,32>\u001b[0m) -> float32_247<1,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1msoftmax[torch.nn.functional]\u001b[0m(float32_246<1,32,32>\u001b[0m, -1, _stacklevel=5) -> float32_247<1,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0msoftmax[torch.Tensor]\u001b[0m(float32_246<1,32,32>\u001b[0m, -1) -> float32_247<1,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_208<1,32,45,80>\u001b[0m, 1, 32, -1) -> float32_248<1,32,3600>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mbmm[torch]\u001b[0m(float32_247<1,32,32>\u001b[0m, float32_248<1,32,3600>\u001b[0m) -> float32_249<1,32,3600>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_249<1,32,3600>\u001b[0m, 1, 32, 45, 80) -> float32_250<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(\u001b[4mfloat32_251<1>\u001b[0m, float32_250<1,32,45,80>\u001b[0m) -> float32_252<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_251<1>\u001b[0m, float32_250<1,32,45,80>\u001b[0m) -> float32_252<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_252<1,32,45,80>\u001b[0m, float32_208<1,32,45,80>\u001b[0m) -> float32_253<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_252<1,32,45,80>\u001b[0m, float32_208<1,32,45,80>\u001b[0m) -> float32_253<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCBR[model.TwinLite]\u001b[0m(float32_253<1,32,45,80>\u001b[0m) -> float32_262<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_253<1,32,45,80>\u001b[0m) -> float32_255<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_253<1,32,45,80>\u001b[0m, float32_254<32,32,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_255<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_255<1,32,45,80>\u001b[0m) -> float32_260<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_255<1,32,45,80>\u001b[0m, float32_256<32>\u001b[0m, float32_257<32>\u001b[0m, float32_258<32>\u001b[0m, float32_259<32>\u001b[0m, False, 0.1, 0.001) -> float32_260<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_255<1,32,45,80>\u001b[0m, float32_258<32>\u001b[0m, float32_259<32>\u001b[0m, float32_256<32>\u001b[0m, float32_257<32>\u001b[0m, False, 0.1, 0.001, True) -> float32_260<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mPReLU[torch.nn.modules.activation]\u001b[0m(float32_260<1,32,45,80>\u001b[0m) -> float32_262<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mprelu[torch.nn.functional]\u001b[0m(float32_260<1,32,45,80>\u001b[0m, float32_261<32>\u001b[0m) -> float32_262<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_238<1,32,45,80>\u001b[0m, float32_262<1,32,45,80>\u001b[0m) -> float32_263<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_238<1,32,45,80>\u001b[0m, float32_262<1,32,45,80>\u001b[0m) -> float32_263<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mCBR[model.TwinLite]\u001b[0m(float32_263<1,32,45,80>\u001b[0m) -> float32_272<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_263<1,32,45,80>\u001b[0m) -> float32_265<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_263<1,32,45,80>\u001b[0m, float32_264<32,32,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_265<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_265<1,32,45,80>\u001b[0m) -> float32_270<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_265<1,32,45,80>\u001b[0m, float32_266<32>\u001b[0m, float32_267<32>\u001b[0m, float32_268<32>\u001b[0m, float32_269<32>\u001b[0m, False, 0.1, 0.001) -> float32_270<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_265<1,32,45,80>\u001b[0m, float32_268<32>\u001b[0m, float32_269<32>\u001b[0m, float32_266<32>\u001b[0m, float32_267<32>\u001b[0m, False, 0.1, 0.001, True) -> float32_270<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mPReLU[torch.nn.modules.activation]\u001b[0m(float32_270<1,32,45,80>\u001b[0m) -> float32_272<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mprelu[torch.nn.functional]\u001b[0m(float32_270<1,32,45,80>\u001b[0m, float32_271<32>\u001b[0m) -> float32_272<1,32,45,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mUPx2[model.TwinLite]\u001b[0m(float32_272<1,32,45,80>\u001b[0m) -> float32_281<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConvTranspose2d[torch.nn.modules.conv]\u001b[0m(float32_272<1,32,45,80>\u001b[0m) -> float32_274<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv_transpose2d[torch.nn.functional]\u001b[0m(float32_272<1,32,45,80>\u001b[0m, float32_273<32,16,2,2>\u001b[0m, None, (2, 2), (0, 0), (0, 0), 1, (1, 1)) -> float32_274<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_274<1,16,90,160>\u001b[0m) -> float32_279<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_274<1,16,90,160>\u001b[0m, float32_275<16>\u001b[0m, float32_276<16>\u001b[0m, float32_277<16>\u001b[0m, float32_278<16>\u001b[0m, False, 0.1, 0.001) -> float32_279<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_274<1,16,90,160>\u001b[0m, float32_277<16>\u001b[0m, float32_278<16>\u001b[0m, float32_275<16>\u001b[0m, float32_276<16>\u001b[0m, False, 0.1, 0.001, True) -> float32_279<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mPReLU[torch.nn.modules.activation]\u001b[0m(float32_279<1,16,90,160>\u001b[0m) -> float32_281<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mprelu[torch.nn.functional]\u001b[0m(float32_279<1,16,90,160>\u001b[0m, float32_280<16>\u001b[0m) -> float32_281<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mUPx2[model.TwinLite]\u001b[0m(float32_281<1,16,90,160>\u001b[0m) -> float32_290<1,8,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConvTranspose2d[torch.nn.modules.conv]\u001b[0m(float32_281<1,16,90,160>\u001b[0m) -> float32_283<1,8,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv_transpose2d[torch.nn.functional]\u001b[0m(float32_281<1,16,90,160>\u001b[0m, float32_282<16,8,2,2>\u001b[0m, None, (2, 2), (0, 0), (0, 0), 1, (1, 1)) -> float32_283<1,8,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_283<1,8,180,320>\u001b[0m) -> float32_288<1,8,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_283<1,8,180,320>\u001b[0m, float32_284<8>\u001b[0m, float32_285<8>\u001b[0m, float32_286<8>\u001b[0m, float32_287<8>\u001b[0m, False, 0.1, 0.001) -> float32_288<1,8,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_283<1,8,180,320>\u001b[0m, float32_286<8>\u001b[0m, float32_287<8>\u001b[0m, float32_284<8>\u001b[0m, float32_285<8>\u001b[0m, False, 0.1, 0.001, True) -> float32_288<1,8,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mPReLU[torch.nn.modules.activation]\u001b[0m(float32_288<1,8,180,320>\u001b[0m) -> float32_290<1,8,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mprelu[torch.nn.functional]\u001b[0m(float32_288<1,8,180,320>\u001b[0m, float32_289<8>\u001b[0m) -> float32_290<1,8,180,320>\u001b[0m\n",
      "\u001b[32m ├·\u001b[0m \u001b[32mUPx2[model.TwinLite]\u001b[0m(float32_290<1,8,180,320>\u001b[0m) -> float32_299<1,2,360,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConvTranspose2d[torch.nn.modules.conv]\u001b[0m(float32_290<1,8,180,320>\u001b[0m) -> float32_292<1,2,360,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv_transpose2d[torch.nn.functional]\u001b[0m(float32_290<1,8,180,320>\u001b[0m, float32_291<8,2,2,2>\u001b[0m, None, (2, 2), (0, 0), (0, 0), 1, (1, 1)) -> float32_292<1,2,360,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_292<1,2,360,640>\u001b[0m) -> float32_297<1,2,360,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_292<1,2,360,640>\u001b[0m, float32_293<2>\u001b[0m, float32_294<2>\u001b[0m, float32_295<2>\u001b[0m, float32_296<2>\u001b[0m, False, 0.1, 0.001) -> float32_297<1,2,360,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_292<1,2,360,640>\u001b[0m, float32_295<2>\u001b[0m, float32_296<2>\u001b[0m, float32_293<2>\u001b[0m, float32_294<2>\u001b[0m, False, 0.1, 0.001, True) -> float32_297<1,2,360,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mPReLU[torch.nn.modules.activation]\u001b[0m(float32_297<1,2,360,640>\u001b[0m) -> float32_299<1,2,360,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mprelu[torch.nn.functional]\u001b[0m(float32_297<1,2,360,640>\u001b[0m, float32_298<2>\u001b[0m) -> float32_299<1,2,360,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mUPx2[model.TwinLite]\u001b[0m(float32_272<1,32,45,80>\u001b[0m) -> float32_308<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConvTranspose2d[torch.nn.modules.conv]\u001b[0m(float32_272<1,32,45,80>\u001b[0m) -> float32_301<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv_transpose2d[torch.nn.functional]\u001b[0m(float32_272<1,32,45,80>\u001b[0m, float32_300<32,16,2,2>\u001b[0m, None, (2, 2), (0, 0), (0, 0), 1, (1, 1)) -> float32_301<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_301<1,16,90,160>\u001b[0m) -> float32_306<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_301<1,16,90,160>\u001b[0m, float32_302<16>\u001b[0m, float32_303<16>\u001b[0m, float32_304<16>\u001b[0m, float32_305<16>\u001b[0m, False, 0.1, 0.001) -> float32_306<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_301<1,16,90,160>\u001b[0m, float32_304<16>\u001b[0m, float32_305<16>\u001b[0m, float32_302<16>\u001b[0m, float32_303<16>\u001b[0m, False, 0.1, 0.001, True) -> float32_306<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mPReLU[torch.nn.modules.activation]\u001b[0m(float32_306<1,16,90,160>\u001b[0m) -> float32_308<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mprelu[torch.nn.functional]\u001b[0m(float32_306<1,16,90,160>\u001b[0m, float32_307<16>\u001b[0m) -> float32_308<1,16,90,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mUPx2[model.TwinLite]\u001b[0m(float32_308<1,16,90,160>\u001b[0m) -> float32_317<1,8,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConvTranspose2d[torch.nn.modules.conv]\u001b[0m(float32_308<1,16,90,160>\u001b[0m) -> float32_310<1,8,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv_transpose2d[torch.nn.functional]\u001b[0m(float32_308<1,16,90,160>\u001b[0m, float32_309<16,8,2,2>\u001b[0m, None, (2, 2), (0, 0), (0, 0), 1, (1, 1)) -> float32_310<1,8,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_310<1,8,180,320>\u001b[0m) -> float32_315<1,8,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_310<1,8,180,320>\u001b[0m, float32_311<8>\u001b[0m, float32_312<8>\u001b[0m, float32_313<8>\u001b[0m, float32_314<8>\u001b[0m, False, 0.1, 0.001) -> float32_315<1,8,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_310<1,8,180,320>\u001b[0m, float32_313<8>\u001b[0m, float32_314<8>\u001b[0m, float32_311<8>\u001b[0m, float32_312<8>\u001b[0m, False, 0.1, 0.001, True) -> float32_315<1,8,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mPReLU[torch.nn.modules.activation]\u001b[0m(float32_315<1,8,180,320>\u001b[0m) -> float32_317<1,8,180,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mprelu[torch.nn.functional]\u001b[0m(float32_315<1,8,180,320>\u001b[0m, float32_316<8>\u001b[0m) -> float32_317<1,8,180,320>\u001b[0m\n",
      "\u001b[32m ├·\u001b[0m \u001b[32mUPx2[model.TwinLite]\u001b[0m(float32_317<1,8,180,320>\u001b[0m) -> float32_326<1,2,360,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConvTranspose2d[torch.nn.modules.conv]\u001b[0m(float32_317<1,8,180,320>\u001b[0m) -> float32_319<1,2,360,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv_transpose2d[torch.nn.functional]\u001b[0m(float32_317<1,8,180,320>\u001b[0m, float32_318<8,2,2,2>\u001b[0m, None, (2, 2), (0, 0), (0, 0), 1, (1, 1)) -> float32_319<1,2,360,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_319<1,2,360,640>\u001b[0m) -> float32_324<1,2,360,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_319<1,2,360,640>\u001b[0m, float32_320<2>\u001b[0m, float32_321<2>\u001b[0m, float32_322<2>\u001b[0m, float32_323<2>\u001b[0m, False, 0.1, 0.001) -> float32_324<1,2,360,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_319<1,2,360,640>\u001b[0m, float32_322<2>\u001b[0m, float32_323<2>\u001b[0m, float32_320<2>\u001b[0m, float32_321<2>\u001b[0m, False, 0.1, 0.001, True) -> float32_324<1,2,360,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mPReLU[torch.nn.modules.activation]\u001b[0m(float32_324<1,2,360,640>\u001b[0m) -> float32_326<1,2,360,640>\u001b[0m\n",
      "\u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mprelu[torch.nn.functional]\u001b[0m(float32_324<1,2,360,640>\u001b[0m, float32_325<2>\u001b[0m) -> float32_326<1,2,360,640>\u001b[0m\n",
      "\n",
      "[Nobuco] Conversion complete. Elapsed time: 19.66 sec.\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 3, dataset.H_, dataset.W_)\n",
    "keras_model = pytorch_to_keras(model, [input], inputs_channel_order=ChannelOrder.TENSORFLOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbio28vqj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbio28vqj/assets\n",
      "2024-08-20 10:44:29.645848: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-08-20 10:44:29.645879: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-08-20 10:44:29.646675: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpbio28vqj\n",
      "2024-08-20 10:44:29.671011: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-08-20 10:44:29.671040: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpbio28vqj\n",
      "2024-08-20 10:44:29.719476: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-08-20 10:44:29.741840: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-08-20 10:44:30.101655: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpbio28vqj\n",
      "2024-08-20 10:44:30.275644: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 628971 microseconds.\n",
      "2024-08-20 10:44:30.510271: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 129, Total Ops 332, % non-converted = 38.86 %\n",
      " * 129 ARITH ops\n",
      "\n",
      "- arith.constant:  129 occurrences  (f32: 115, i32: 14)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 36)\n",
      "  (f32: 2)\n",
      "  (f32: 4)\n",
      "  (f32: 10)\n",
      "  (f32: 52)\n",
      "  (f32: 10)\n",
      "  (f32: 44)\n",
      "  (f32: 20)\n",
      "  (f32: 1)\n",
      "  (f32: 6)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 6)\n",
      "  (f32: 6)\n",
      "2024-08-20 10:44:30.945973: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 8.294 G  ops, equivalently 4.147 G  MACs\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "with open(f\"models/twinlitenet.tflite\", 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_erm9o0m/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_erm9o0m/assets\n",
      "/home/ubuntadmin/Desktop/TwinLiteNet/venv/lib/python3.11/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-08-20 10:44:50.171584: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-08-20 10:44:50.171636: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-08-20 10:44:50.172007: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp_erm9o0m\n",
      "2024-08-20 10:44:50.206305: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-08-20 10:44:50.206336: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp_erm9o0m\n",
      "2024-08-20 10:44:50.284272: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-08-20 10:44:50.675621: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp_erm9o0m\n",
      "2024-08-20 10:44:50.869793: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 697791 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 129, Total Ops 332, % non-converted = 38.86 %\n",
      " * 129 ARITH ops\n",
      "\n",
      "- arith.constant:  129 occurrences  (f32: 115, i32: 14)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 36)\n",
      "  (f32: 2)\n",
      "  (f32: 4)\n",
      "  (f32: 10)\n",
      "  (f32: 52)\n",
      "  (f32: 10)\n",
      "  (f32: 44)\n",
      "  (f32: 20)\n",
      "  (f32: 1)\n",
      "  (f32: 6)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 6)\n",
      "  (f32: 6)\n",
      "2024-08-20 10:44:51.514513: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 8.294 G  ops, equivalently 4.147 G  MACs\n",
      "100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n",
      "2024-08-20 10:45:01.644457: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 8.294 G  ops, equivalently 4.147 G  MACs\n"
     ]
    }
   ],
   "source": [
    "def representative_dataset_gen():\n",
    "\tfor img_name, input, (seg_da, seg_ll) in tqdm(dataset):\n",
    "\t\tinput = input.float() / 255.0\n",
    "\t\tinput = input.numpy()\n",
    "\t\tinput = np.expand_dims(input, axis=0)\n",
    "\t\tinput = np.transpose(input, (0, 2, 3, 1))\n",
    "\t\tyield [input]\n",
    "\t\t\n",
    "qt_converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
    "qt_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "qt_converter.representative_dataset = representative_dataset_gen\n",
    "\n",
    "tflite_model = qt_converter.convert()\n",
    "with open(f\"models/twinlitenet_qt.tflite\", 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

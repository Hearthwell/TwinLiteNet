{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 10:41:37.361460: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-20 10:41:37.361527: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-20 10:41:37.387133: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-20 10:41:37.449929: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-20 10:41:38.622988: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from nobuco import pytorch_to_keras, ChannelOrder\n",
    "\n",
    "from model.TwinLiteRELU import TwinLiteNet as TwinLiteNetRELU \n",
    "from DataSet import CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntadmin/Desktop/TwinLiteNet/venv/lib/python3.11/site-packages/nobuco/trace/trace.py:366: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  outputs = orig_method(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TwinLiteNet(\n",
       "  (encoder): ESPNet_Encoder(\n",
       "    (level1): CBR(\n",
       "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (sample1): InputProjectionA(\n",
       "      (pool): ModuleList(\n",
       "        (0): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "      )\n",
       "    )\n",
       "    (sample2): InputProjectionA(\n",
       "      (pool): ModuleList(\n",
       "        (0-1): 2 x AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "      )\n",
       "    )\n",
       "    (b1): CBR(\n",
       "      (conv): Conv2d(19, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(19, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (level2_0): DownSamplerB(\n",
       "      (c1): C(\n",
       "        (conv): Conv2d(19, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (d1): CDilated(\n",
       "        (conv): Conv2d(12, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (d2): CDilated(\n",
       "        (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      )\n",
       "      (d4): CDilated(\n",
       "        (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      )\n",
       "      (d8): CDilated(\n",
       "        (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
       "      )\n",
       "      (d16): CDilated(\n",
       "        (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
       "      )\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (level2): ModuleList(\n",
       "      (0-1): 2 x DilatedParllelResidualBlockB(\n",
       "        (c1): C(\n",
       "          (conv): Conv2d(64, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (d1): CDilated(\n",
       "          (conv): Conv2d(12, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (d2): CDilated(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        )\n",
       "        (d4): CDilated(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        )\n",
       "        (d8): CDilated(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
       "        )\n",
       "        (d16): CDilated(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
       "        )\n",
       "        (bn): BR(\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (b2): CBR(\n",
       "      (conv): Conv2d(131, 131, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(131, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (level3_0): DownSamplerB(\n",
       "      (c1): C(\n",
       "        (conv): Conv2d(131, 25, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (d1): CDilated(\n",
       "        (conv): Conv2d(25, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (d2): CDilated(\n",
       "        (conv): Conv2d(25, 25, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      )\n",
       "      (d4): CDilated(\n",
       "        (conv): Conv2d(25, 25, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      )\n",
       "      (d8): CDilated(\n",
       "        (conv): Conv2d(25, 25, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
       "      )\n",
       "      (d16): CDilated(\n",
       "        (conv): Conv2d(25, 25, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
       "      )\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (level3): ModuleList(\n",
       "      (0-2): 3 x DilatedParllelResidualBlockB(\n",
       "        (c1): C(\n",
       "          (conv): Conv2d(128, 25, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (d1): CDilated(\n",
       "          (conv): Conv2d(25, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (d2): CDilated(\n",
       "          (conv): Conv2d(25, 25, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        )\n",
       "        (d4): CDilated(\n",
       "          (conv): Conv2d(25, 25, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        )\n",
       "        (d8): CDilated(\n",
       "          (conv): Conv2d(25, 25, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
       "        )\n",
       "        (d16): CDilated(\n",
       "          (conv): Conv2d(25, 25, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
       "        )\n",
       "        (bn): BR(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (b3): CBR(\n",
       "      (conv): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (sa): PAM_Module(\n",
       "      (query_conv): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (key_conv): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (value_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (sc): CAM_Module(\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (conv_sa): CBR(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv_sc): CBR(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (classifier): CBR(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up_1_1): UPx2(\n",
       "    (deconv): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): ReLU(inplace=True)\n",
       "  )\n",
       "  (up_2_1): UPx2(\n",
       "    (deconv): ConvTranspose2d(16, 8, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): ReLU(inplace=True)\n",
       "  )\n",
       "  (up_1_2): UPx2(\n",
       "    (deconv): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): ReLU(inplace=True)\n",
       "  )\n",
       "  (up_2_2): UPx2(\n",
       "    (deconv): ConvTranspose2d(16, 8, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): ReLU(inplace=True)\n",
       "  )\n",
       "  (classifier_1): UPx2(\n",
       "    (deconv): ConvTranspose2d(8, 2, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(2, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): ReLU(inplace=True)\n",
       "  )\n",
       "  (classifier_2): UPx2(\n",
       "    (deconv): ConvTranspose2d(8, 2, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(2, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load('pretrained/epo64_RELU.pth', map_location='cpu')\n",
    "\n",
    "model = nn.Sequential(torch.ao.quantization.QuantStub(), TwinLiteNetRELU(), torch.ao.quantization.DeQuantStub())\n",
    "model.load_state_dict(state_dict)\n",
    "model = model[1]\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"/media/ubuntadmin/67b3a250-6e0f-4a86-b15d-1b302250e0b4/home/ubuntadmin/Desktop/data/datasets/road-segmentation/TwinLiteTree/images\"\n",
    "MAX_CALIBRATION_IMG = 1\n",
    "dataset = CustomDataset(DATASET_PATH, valid=True)\n",
    "dataset.names = dataset.names[:MAX_CALIBRATION_IMG]\n",
    "\n",
    "#HEIGHT_FACTOR = 1.0\n",
    "HEIGHT_FACTOR = 2.0 / 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nobuco] Tracing: 0 ops [00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nobuco] Tracing (DONE): 236 ops [00:02]\n",
      "[Nobuco] Converting: |▏         | 4/162 ops [00:03]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 10:41:56.293248: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nobuco] Converting: |██████▌   | 106/162 ops [00:05]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 10:41:59.215396: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 23040000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nobuco] Converting: |███████   | 114/162 ops [00:06]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 10:41:59.457647: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 23040000 exceeds 10% of free system memory.\n",
      "2024-08-20 10:41:59.461522: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 23040000 exceeds 10% of free system memory.\n",
      "2024-08-20 10:41:59.483652: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 23040000 exceeds 10% of free system memory.\n",
      "2024-08-20 10:41:59.490354: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 23040000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nobuco] Converting (DONE): |██████████| 162/162 ops [00:08]\n",
      "Legend:\n",
      "    \u001b[32mGreen\u001b[0m — conversion successful\n",
      "    \u001b[33mYellow\u001b[0m — conversion imprecise\n",
      "    \u001b[31mRed\u001b[0m — conversion failed\n",
      "    \u001b[31m\u001b[7mRed\u001b[0m — no converter found\n",
      "    \u001b[0m\u001b[1mBold\u001b[0m — conversion applied directly\n",
      "    * — subgraph reused\n",
      "    \u001b[7mTensor\u001b[0m — this output is not dependent on any of subgraph's input tensors\n",
      "    \u001b[4mTensor\u001b[0m — this input is a parameter / constant\n",
      "    \u001b[90mTensor\u001b[0m — this tensor is useless\n",
      "\n",
      "\u001b[32mTwinLiteNet[model.TwinLiteRELU]\u001b[0m(float32_0<1,3,240,640>\u001b[0m) -> (float32_265<1,2,240,640>\u001b[0m, float32_286<1,2,240,640>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32mESPNet_Encoder[model.TwinLiteRELU]\u001b[0m(float32_0<1,3,240,640>\u001b[0m) -> float32_244<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCBR[model.TwinLiteRELU]\u001b[0m(float32_0<1,3,240,640>\u001b[0m) -> float32_7<1,16,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_0<1,3,240,640>\u001b[0m) -> float32_2<1,16,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_0<1,3,240,640>\u001b[0m, float32_1<16,3,3,3>\u001b[0m, None, (2, 2), (1, 1), (1, 1), 1) -> float32_2<1,16,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_2<1,16,120,320>\u001b[0m) -> float32_7<1,16,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_2<1,16,120,320>\u001b[0m, float32_3<16>\u001b[0m, float32_4<16>\u001b[0m, float32_5<16>\u001b[0m, float32_6<16>\u001b[0m, False, 0.1, 0.001) -> float32_7<1,16,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_2<1,16,120,320>\u001b[0m, float32_5<16>\u001b[0m, float32_6<16>\u001b[0m, float32_3<16>\u001b[0m, float32_4<16>\u001b[0m, False, 0.1, 0.001, True) -> float32_7<1,16,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_7<1,16,120,320>\u001b[0m) -> float32_7<1,16,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_7<1,16,120,320>\u001b[0m, inplace=16) -> float32_7<1,16,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_7<1,16,120,320>\u001b[0m) -> float32_7<1,16,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mInputProjectionA[model.TwinLiteRELU]\u001b[0m(float32_0<1,3,240,640>\u001b[0m) -> float32_8<1,3,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_0<1,3,240,640>\u001b[0m) -> float32_8<1,3,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mavg_pool2d[torch.nn.functional]\u001b[0m(float32_0<1,3,240,640>\u001b[0m, 3, 2, 1, False, True, None) -> float32_8<1,3,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mInputProjectionA[model.TwinLiteRELU]\u001b[0m(float32_0<1,3,240,640>\u001b[0m) -> float32_10<1,3,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_0<1,3,240,640>\u001b[0m) -> float32_9<1,3,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mavg_pool2d[torch.nn.functional]\u001b[0m(float32_0<1,3,240,640>\u001b[0m, 3, 2, 1, False, True, None) -> float32_9<1,3,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_9<1,3,120,320>\u001b[0m) -> float32_10<1,3,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mavg_pool2d[torch.nn.functional]\u001b[0m(float32_9<1,3,120,320>\u001b[0m, 3, 2, 1, False, True, None) -> float32_10<1,3,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_7<1,16,120,320>\u001b[0m, float32_8<1,3,120,320>\u001b[0m], 1) -> float32_11<1,19,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCBR[model.TwinLiteRELU]\u001b[0m(float32_11<1,19,120,320>\u001b[0m) -> float32_18<1,19,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_11<1,19,120,320>\u001b[0m) -> float32_13<1,19,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_11<1,19,120,320>\u001b[0m, float32_12<19,19,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_13<1,19,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_13<1,19,120,320>\u001b[0m) -> float32_18<1,19,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_13<1,19,120,320>\u001b[0m, float32_14<19>\u001b[0m, float32_15<19>\u001b[0m, float32_16<19>\u001b[0m, float32_17<19>\u001b[0m, False, 0.1, 0.001) -> float32_18<1,19,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_13<1,19,120,320>\u001b[0m, float32_16<19>\u001b[0m, float32_17<19>\u001b[0m, float32_14<19>\u001b[0m, float32_15<19>\u001b[0m, False, 0.1, 0.001, True) -> float32_18<1,19,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_18<1,19,120,320>\u001b[0m) -> float32_18<1,19,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_18<1,19,120,320>\u001b[0m, inplace=19) -> float32_18<1,19,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_18<1,19,120,320>\u001b[0m) -> float32_18<1,19,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mDownSamplerB[model.TwinLiteRELU]\u001b[0m(float32_18<1,19,120,320>\u001b[0m) -> float32_39<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mC[model.TwinLiteRELU]\u001b[0m(float32_18<1,19,120,320>\u001b[0m) -> float32_20<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_18<1,19,120,320>\u001b[0m) -> float32_20<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_18<1,19,120,320>\u001b[0m, float32_19<12,19,3,3>\u001b[0m, None, (2, 2), (1, 1), (1, 1), 1) -> float32_20<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_20<1,12,60,160>\u001b[0m) -> float32_22<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_20<1,12,60,160>\u001b[0m) -> float32_22<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_20<1,12,60,160>\u001b[0m, float32_21<16,12,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_22<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_20<1,12,60,160>\u001b[0m) -> float32_24<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_20<1,12,60,160>\u001b[0m) -> float32_24<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_20<1,12,60,160>\u001b[0m, float32_23<12,12,3,3>\u001b[0m, None, (1, 1), (2, 2), (2, 2), 1) -> float32_24<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_20<1,12,60,160>\u001b[0m) -> float32_26<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_20<1,12,60,160>\u001b[0m) -> float32_26<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_20<1,12,60,160>\u001b[0m, float32_25<12,12,3,3>\u001b[0m, None, (1, 1), (4, 4), (4, 4), 1) -> float32_26<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_20<1,12,60,160>\u001b[0m) -> float32_28<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_20<1,12,60,160>\u001b[0m) -> float32_28<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_20<1,12,60,160>\u001b[0m, float32_27<12,12,3,3>\u001b[0m, None, (1, 1), (8, 8), (8, 8), 1) -> float32_28<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_20<1,12,60,160>\u001b[0m) -> float32_30<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_20<1,12,60,160>\u001b[0m) -> float32_30<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_20<1,12,60,160>\u001b[0m, float32_29<12,12,3,3>\u001b[0m, None, (1, 1), (16, 16), (16, 16), 1) -> float32_30<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_24<1,12,60,160>\u001b[0m, float32_26<1,12,60,160>\u001b[0m) -> float32_31<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_24<1,12,60,160>\u001b[0m, float32_26<1,12,60,160>\u001b[0m) -> float32_31<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_31<1,12,60,160>\u001b[0m, float32_28<1,12,60,160>\u001b[0m) -> float32_32<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_31<1,12,60,160>\u001b[0m, float32_28<1,12,60,160>\u001b[0m) -> float32_32<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_32<1,12,60,160>\u001b[0m, float32_30<1,12,60,160>\u001b[0m) -> float32_33<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_32<1,12,60,160>\u001b[0m, float32_30<1,12,60,160>\u001b[0m) -> float32_33<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_22<1,16,60,160>\u001b[0m, float32_24<1,12,60,160>\u001b[0m, float32_31<1,12,60,160>\u001b[0m, float32_32<1,12,60,160>\u001b[0m, float32_33<1,12,60,160>\u001b[0m], 1) -> float32_34<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_34<1,64,60,160>\u001b[0m) -> float32_39<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_34<1,64,60,160>\u001b[0m, float32_35<64>\u001b[0m, float32_36<64>\u001b[0m, float32_37<64>\u001b[0m, float32_38<64>\u001b[0m, False, 0.1, 0.001) -> float32_39<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_34<1,64,60,160>\u001b[0m, float32_37<64>\u001b[0m, float32_38<64>\u001b[0m, float32_35<64>\u001b[0m, float32_36<64>\u001b[0m, False, 0.1, 0.001, True) -> float32_39<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_39<1,64,60,160>\u001b[0m) -> float32_39<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_39<1,64,60,160>\u001b[0m, inplace=64) -> float32_39<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_39<1,64,60,160>\u001b[0m) -> float32_39<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mDilatedParllelResidualBlockB[model.TwinLiteRELU]\u001b[0m(float32_39<1,64,60,160>\u001b[0m) -> float32_61<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mC[model.TwinLiteRELU]\u001b[0m(float32_39<1,64,60,160>\u001b[0m) -> float32_41<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_39<1,64,60,160>\u001b[0m) -> float32_41<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_39<1,64,60,160>\u001b[0m, float32_40<12,64,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_41<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_41<1,12,60,160>\u001b[0m) -> float32_43<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_41<1,12,60,160>\u001b[0m) -> float32_43<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_41<1,12,60,160>\u001b[0m, float32_42<16,12,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_43<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_41<1,12,60,160>\u001b[0m) -> float32_45<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_41<1,12,60,160>\u001b[0m) -> float32_45<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_41<1,12,60,160>\u001b[0m, float32_44<12,12,3,3>\u001b[0m, None, (1, 1), (2, 2), (2, 2), 1) -> float32_45<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_41<1,12,60,160>\u001b[0m) -> float32_47<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_41<1,12,60,160>\u001b[0m) -> float32_47<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_41<1,12,60,160>\u001b[0m, float32_46<12,12,3,3>\u001b[0m, None, (1, 1), (4, 4), (4, 4), 1) -> float32_47<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_41<1,12,60,160>\u001b[0m) -> float32_49<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_41<1,12,60,160>\u001b[0m) -> float32_49<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_41<1,12,60,160>\u001b[0m, float32_48<12,12,3,3>\u001b[0m, None, (1, 1), (8, 8), (8, 8), 1) -> float32_49<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_41<1,12,60,160>\u001b[0m) -> float32_51<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_41<1,12,60,160>\u001b[0m) -> float32_51<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_41<1,12,60,160>\u001b[0m, float32_50<12,12,3,3>\u001b[0m, None, (1, 1), (16, 16), (16, 16), 1) -> float32_51<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_45<1,12,60,160>\u001b[0m, float32_47<1,12,60,160>\u001b[0m) -> float32_52<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_45<1,12,60,160>\u001b[0m, float32_47<1,12,60,160>\u001b[0m) -> float32_52<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_52<1,12,60,160>\u001b[0m, float32_49<1,12,60,160>\u001b[0m) -> float32_53<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_52<1,12,60,160>\u001b[0m, float32_49<1,12,60,160>\u001b[0m) -> float32_53<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_53<1,12,60,160>\u001b[0m, float32_51<1,12,60,160>\u001b[0m) -> float32_54<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_53<1,12,60,160>\u001b[0m, float32_51<1,12,60,160>\u001b[0m) -> float32_54<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_43<1,16,60,160>\u001b[0m, float32_45<1,12,60,160>\u001b[0m, float32_52<1,12,60,160>\u001b[0m, float32_53<1,12,60,160>\u001b[0m, float32_54<1,12,60,160>\u001b[0m], 1) -> float32_55<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_39<1,64,60,160>\u001b[0m, float32_55<1,64,60,160>\u001b[0m) -> float32_56<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_39<1,64,60,160>\u001b[0m, float32_55<1,64,60,160>\u001b[0m) -> float32_56<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mBR[model.TwinLiteRELU]\u001b[0m(float32_56<1,64,60,160>\u001b[0m) -> float32_61<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_56<1,64,60,160>\u001b[0m) -> float32_61<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_56<1,64,60,160>\u001b[0m, float32_57<64>\u001b[0m, float32_58<64>\u001b[0m, float32_59<64>\u001b[0m, float32_60<64>\u001b[0m, False, 0.1, 0.001) -> float32_61<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_56<1,64,60,160>\u001b[0m, float32_59<64>\u001b[0m, float32_60<64>\u001b[0m, float32_57<64>\u001b[0m, float32_58<64>\u001b[0m, False, 0.1, 0.001, True) -> float32_61<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_61<1,64,60,160>\u001b[0m) -> float32_61<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_61<1,64,60,160>\u001b[0m, inplace=64) -> float32_61<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_61<1,64,60,160>\u001b[0m) -> float32_61<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mDilatedParllelResidualBlockB[model.TwinLiteRELU]\u001b[0m(float32_61<1,64,60,160>\u001b[0m) -> float32_83<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mC[model.TwinLiteRELU]\u001b[0m(float32_61<1,64,60,160>\u001b[0m) -> float32_63<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_61<1,64,60,160>\u001b[0m) -> float32_63<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_61<1,64,60,160>\u001b[0m, float32_62<12,64,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_63<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_63<1,12,60,160>\u001b[0m) -> float32_65<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_63<1,12,60,160>\u001b[0m) -> float32_65<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_63<1,12,60,160>\u001b[0m, float32_64<16,12,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_65<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_63<1,12,60,160>\u001b[0m) -> float32_67<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_63<1,12,60,160>\u001b[0m) -> float32_67<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_63<1,12,60,160>\u001b[0m, float32_66<12,12,3,3>\u001b[0m, None, (1, 1), (2, 2), (2, 2), 1) -> float32_67<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_63<1,12,60,160>\u001b[0m) -> float32_69<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_63<1,12,60,160>\u001b[0m) -> float32_69<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_63<1,12,60,160>\u001b[0m, float32_68<12,12,3,3>\u001b[0m, None, (1, 1), (4, 4), (4, 4), 1) -> float32_69<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_63<1,12,60,160>\u001b[0m) -> float32_71<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_63<1,12,60,160>\u001b[0m) -> float32_71<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_63<1,12,60,160>\u001b[0m, float32_70<12,12,3,3>\u001b[0m, None, (1, 1), (8, 8), (8, 8), 1) -> float32_71<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_63<1,12,60,160>\u001b[0m) -> float32_73<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_63<1,12,60,160>\u001b[0m) -> float32_73<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_63<1,12,60,160>\u001b[0m, float32_72<12,12,3,3>\u001b[0m, None, (1, 1), (16, 16), (16, 16), 1) -> float32_73<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_67<1,12,60,160>\u001b[0m, float32_69<1,12,60,160>\u001b[0m) -> float32_74<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_67<1,12,60,160>\u001b[0m, float32_69<1,12,60,160>\u001b[0m) -> float32_74<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_74<1,12,60,160>\u001b[0m, float32_71<1,12,60,160>\u001b[0m) -> float32_75<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_74<1,12,60,160>\u001b[0m, float32_71<1,12,60,160>\u001b[0m) -> float32_75<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_75<1,12,60,160>\u001b[0m, float32_73<1,12,60,160>\u001b[0m) -> float32_76<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_75<1,12,60,160>\u001b[0m, float32_73<1,12,60,160>\u001b[0m) -> float32_76<1,12,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_65<1,16,60,160>\u001b[0m, float32_67<1,12,60,160>\u001b[0m, float32_74<1,12,60,160>\u001b[0m, float32_75<1,12,60,160>\u001b[0m, float32_76<1,12,60,160>\u001b[0m], 1) -> float32_77<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_61<1,64,60,160>\u001b[0m, float32_77<1,64,60,160>\u001b[0m) -> float32_78<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_61<1,64,60,160>\u001b[0m, float32_77<1,64,60,160>\u001b[0m) -> float32_78<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mBR[model.TwinLiteRELU]\u001b[0m(float32_78<1,64,60,160>\u001b[0m) -> float32_83<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_78<1,64,60,160>\u001b[0m) -> float32_83<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_78<1,64,60,160>\u001b[0m, float32_79<64>\u001b[0m, float32_80<64>\u001b[0m, float32_81<64>\u001b[0m, float32_82<64>\u001b[0m, False, 0.1, 0.001) -> float32_83<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_78<1,64,60,160>\u001b[0m, float32_81<64>\u001b[0m, float32_82<64>\u001b[0m, float32_79<64>\u001b[0m, float32_80<64>\u001b[0m, False, 0.1, 0.001, True) -> float32_83<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_83<1,64,60,160>\u001b[0m) -> float32_83<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_83<1,64,60,160>\u001b[0m, inplace=64) -> float32_83<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_83<1,64,60,160>\u001b[0m) -> float32_83<1,64,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_83<1,64,60,160>\u001b[0m, float32_39<1,64,60,160>\u001b[0m, float32_10<1,3,60,160>\u001b[0m], 1) -> float32_84<1,131,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCBR[model.TwinLiteRELU]\u001b[0m(float32_84<1,131,60,160>\u001b[0m) -> float32_91<1,131,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_84<1,131,60,160>\u001b[0m) -> float32_86<1,131,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_84<1,131,60,160>\u001b[0m, float32_85<131,131,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_86<1,131,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_86<1,131,60,160>\u001b[0m) -> float32_91<1,131,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_86<1,131,60,160>\u001b[0m, float32_87<131>\u001b[0m, float32_88<131>\u001b[0m, float32_89<131>\u001b[0m, float32_90<131>\u001b[0m, False, 0.1, 0.001) -> float32_91<1,131,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_86<1,131,60,160>\u001b[0m, float32_89<131>\u001b[0m, float32_90<131>\u001b[0m, float32_87<131>\u001b[0m, float32_88<131>\u001b[0m, False, 0.1, 0.001, True) -> float32_91<1,131,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_91<1,131,60,160>\u001b[0m) -> float32_91<1,131,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_91<1,131,60,160>\u001b[0m, inplace=131) -> float32_91<1,131,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_91<1,131,60,160>\u001b[0m) -> float32_91<1,131,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mDownSamplerB[model.TwinLiteRELU]\u001b[0m(float32_91<1,131,60,160>\u001b[0m) -> float32_112<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mC[model.TwinLiteRELU]\u001b[0m(float32_91<1,131,60,160>\u001b[0m) -> float32_93<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_91<1,131,60,160>\u001b[0m) -> float32_93<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_91<1,131,60,160>\u001b[0m, float32_92<25,131,3,3>\u001b[0m, None, (2, 2), (1, 1), (1, 1), 1) -> float32_93<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_93<1,25,30,80>\u001b[0m) -> float32_95<1,28,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_93<1,25,30,80>\u001b[0m) -> float32_95<1,28,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_93<1,25,30,80>\u001b[0m, float32_94<28,25,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_95<1,28,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_93<1,25,30,80>\u001b[0m) -> float32_97<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_93<1,25,30,80>\u001b[0m) -> float32_97<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_93<1,25,30,80>\u001b[0m, float32_96<25,25,3,3>\u001b[0m, None, (1, 1), (2, 2), (2, 2), 1) -> float32_97<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_93<1,25,30,80>\u001b[0m) -> float32_99<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_93<1,25,30,80>\u001b[0m) -> float32_99<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_93<1,25,30,80>\u001b[0m, float32_98<25,25,3,3>\u001b[0m, None, (1, 1), (4, 4), (4, 4), 1) -> float32_99<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_93<1,25,30,80>\u001b[0m) -> float32_101<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_93<1,25,30,80>\u001b[0m) -> float32_101<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_93<1,25,30,80>\u001b[0m, float32_100<25,25,3,3>\u001b[0m, None, (1, 1), (8, 8), (8, 8), 1) -> float32_101<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_93<1,25,30,80>\u001b[0m) -> float32_103<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_93<1,25,30,80>\u001b[0m) -> float32_103<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_93<1,25,30,80>\u001b[0m, float32_102<25,25,3,3>\u001b[0m, None, (1, 1), (16, 16), (16, 16), 1) -> float32_103<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_97<1,25,30,80>\u001b[0m, float32_99<1,25,30,80>\u001b[0m) -> float32_104<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_97<1,25,30,80>\u001b[0m, float32_99<1,25,30,80>\u001b[0m) -> float32_104<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_104<1,25,30,80>\u001b[0m, float32_101<1,25,30,80>\u001b[0m) -> float32_105<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_104<1,25,30,80>\u001b[0m, float32_101<1,25,30,80>\u001b[0m) -> float32_105<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_105<1,25,30,80>\u001b[0m, float32_103<1,25,30,80>\u001b[0m) -> float32_106<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_105<1,25,30,80>\u001b[0m, float32_103<1,25,30,80>\u001b[0m) -> float32_106<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_95<1,28,30,80>\u001b[0m, float32_97<1,25,30,80>\u001b[0m, float32_104<1,25,30,80>\u001b[0m, float32_105<1,25,30,80>\u001b[0m, float32_106<1,25,30,80>\u001b[0m], 1) -> float32_107<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_107<1,128,30,80>\u001b[0m) -> float32_112<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_107<1,128,30,80>\u001b[0m, float32_108<128>\u001b[0m, float32_109<128>\u001b[0m, float32_110<128>\u001b[0m, float32_111<128>\u001b[0m, False, 0.1, 0.001) -> float32_112<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_107<1,128,30,80>\u001b[0m, float32_110<128>\u001b[0m, float32_111<128>\u001b[0m, float32_108<128>\u001b[0m, float32_109<128>\u001b[0m, False, 0.1, 0.001, True) -> float32_112<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_112<1,128,30,80>\u001b[0m) -> float32_112<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_112<1,128,30,80>\u001b[0m, inplace=128) -> float32_112<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_112<1,128,30,80>\u001b[0m) -> float32_112<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mDilatedParllelResidualBlockB[model.TwinLiteRELU]\u001b[0m(float32_112<1,128,30,80>\u001b[0m) -> float32_134<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mC[model.TwinLiteRELU]\u001b[0m(float32_112<1,128,30,80>\u001b[0m) -> float32_114<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_112<1,128,30,80>\u001b[0m) -> float32_114<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_112<1,128,30,80>\u001b[0m, float32_113<25,128,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_114<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_114<1,25,30,80>\u001b[0m) -> float32_116<1,28,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_114<1,25,30,80>\u001b[0m) -> float32_116<1,28,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_114<1,25,30,80>\u001b[0m, float32_115<28,25,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_116<1,28,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_114<1,25,30,80>\u001b[0m) -> float32_118<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_114<1,25,30,80>\u001b[0m) -> float32_118<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_114<1,25,30,80>\u001b[0m, float32_117<25,25,3,3>\u001b[0m, None, (1, 1), (2, 2), (2, 2), 1) -> float32_118<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_114<1,25,30,80>\u001b[0m) -> float32_120<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_114<1,25,30,80>\u001b[0m) -> float32_120<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_114<1,25,30,80>\u001b[0m, float32_119<25,25,3,3>\u001b[0m, None, (1, 1), (4, 4), (4, 4), 1) -> float32_120<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_114<1,25,30,80>\u001b[0m) -> float32_122<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_114<1,25,30,80>\u001b[0m) -> float32_122<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_114<1,25,30,80>\u001b[0m, float32_121<25,25,3,3>\u001b[0m, None, (1, 1), (8, 8), (8, 8), 1) -> float32_122<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_114<1,25,30,80>\u001b[0m) -> float32_124<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_114<1,25,30,80>\u001b[0m) -> float32_124<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_114<1,25,30,80>\u001b[0m, float32_123<25,25,3,3>\u001b[0m, None, (1, 1), (16, 16), (16, 16), 1) -> float32_124<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_118<1,25,30,80>\u001b[0m, float32_120<1,25,30,80>\u001b[0m) -> float32_125<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_118<1,25,30,80>\u001b[0m, float32_120<1,25,30,80>\u001b[0m) -> float32_125<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_125<1,25,30,80>\u001b[0m, float32_122<1,25,30,80>\u001b[0m) -> float32_126<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_125<1,25,30,80>\u001b[0m, float32_122<1,25,30,80>\u001b[0m) -> float32_126<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_126<1,25,30,80>\u001b[0m, float32_124<1,25,30,80>\u001b[0m) -> float32_127<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_126<1,25,30,80>\u001b[0m, float32_124<1,25,30,80>\u001b[0m) -> float32_127<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_116<1,28,30,80>\u001b[0m, float32_118<1,25,30,80>\u001b[0m, float32_125<1,25,30,80>\u001b[0m, float32_126<1,25,30,80>\u001b[0m, float32_127<1,25,30,80>\u001b[0m], 1) -> float32_128<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_112<1,128,30,80>\u001b[0m, float32_128<1,128,30,80>\u001b[0m) -> float32_129<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_112<1,128,30,80>\u001b[0m, float32_128<1,128,30,80>\u001b[0m) -> float32_129<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mBR[model.TwinLiteRELU]\u001b[0m(float32_129<1,128,30,80>\u001b[0m) -> float32_134<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_129<1,128,30,80>\u001b[0m) -> float32_134<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_129<1,128,30,80>\u001b[0m, float32_130<128>\u001b[0m, float32_131<128>\u001b[0m, float32_132<128>\u001b[0m, float32_133<128>\u001b[0m, False, 0.1, 0.001) -> float32_134<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_129<1,128,30,80>\u001b[0m, float32_132<128>\u001b[0m, float32_133<128>\u001b[0m, float32_130<128>\u001b[0m, float32_131<128>\u001b[0m, False, 0.1, 0.001, True) -> float32_134<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_134<1,128,30,80>\u001b[0m) -> float32_134<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_134<1,128,30,80>\u001b[0m, inplace=128) -> float32_134<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_134<1,128,30,80>\u001b[0m) -> float32_134<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mDilatedParllelResidualBlockB[model.TwinLiteRELU]\u001b[0m(float32_134<1,128,30,80>\u001b[0m) -> float32_156<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mC[model.TwinLiteRELU]\u001b[0m(float32_134<1,128,30,80>\u001b[0m) -> float32_136<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_134<1,128,30,80>\u001b[0m) -> float32_136<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_134<1,128,30,80>\u001b[0m, float32_135<25,128,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_136<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_136<1,25,30,80>\u001b[0m) -> float32_138<1,28,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_136<1,25,30,80>\u001b[0m) -> float32_138<1,28,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_136<1,25,30,80>\u001b[0m, float32_137<28,25,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_138<1,28,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_136<1,25,30,80>\u001b[0m) -> float32_140<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_136<1,25,30,80>\u001b[0m) -> float32_140<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_136<1,25,30,80>\u001b[0m, float32_139<25,25,3,3>\u001b[0m, None, (1, 1), (2, 2), (2, 2), 1) -> float32_140<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_136<1,25,30,80>\u001b[0m) -> float32_142<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_136<1,25,30,80>\u001b[0m) -> float32_142<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_136<1,25,30,80>\u001b[0m, float32_141<25,25,3,3>\u001b[0m, None, (1, 1), (4, 4), (4, 4), 1) -> float32_142<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_136<1,25,30,80>\u001b[0m) -> float32_144<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_136<1,25,30,80>\u001b[0m) -> float32_144<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_136<1,25,30,80>\u001b[0m, float32_143<25,25,3,3>\u001b[0m, None, (1, 1), (8, 8), (8, 8), 1) -> float32_144<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_136<1,25,30,80>\u001b[0m) -> float32_146<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_136<1,25,30,80>\u001b[0m) -> float32_146<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_136<1,25,30,80>\u001b[0m, float32_145<25,25,3,3>\u001b[0m, None, (1, 1), (16, 16), (16, 16), 1) -> float32_146<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_140<1,25,30,80>\u001b[0m, float32_142<1,25,30,80>\u001b[0m) -> float32_147<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_140<1,25,30,80>\u001b[0m, float32_142<1,25,30,80>\u001b[0m) -> float32_147<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_147<1,25,30,80>\u001b[0m, float32_144<1,25,30,80>\u001b[0m) -> float32_148<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_147<1,25,30,80>\u001b[0m, float32_144<1,25,30,80>\u001b[0m) -> float32_148<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_148<1,25,30,80>\u001b[0m, float32_146<1,25,30,80>\u001b[0m) -> float32_149<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_148<1,25,30,80>\u001b[0m, float32_146<1,25,30,80>\u001b[0m) -> float32_149<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_138<1,28,30,80>\u001b[0m, float32_140<1,25,30,80>\u001b[0m, float32_147<1,25,30,80>\u001b[0m, float32_148<1,25,30,80>\u001b[0m, float32_149<1,25,30,80>\u001b[0m], 1) -> float32_150<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_134<1,128,30,80>\u001b[0m, float32_150<1,128,30,80>\u001b[0m) -> float32_151<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_134<1,128,30,80>\u001b[0m, float32_150<1,128,30,80>\u001b[0m) -> float32_151<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mBR[model.TwinLiteRELU]\u001b[0m(float32_151<1,128,30,80>\u001b[0m) -> float32_156<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_151<1,128,30,80>\u001b[0m) -> float32_156<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_151<1,128,30,80>\u001b[0m, float32_152<128>\u001b[0m, float32_153<128>\u001b[0m, float32_154<128>\u001b[0m, float32_155<128>\u001b[0m, False, 0.1, 0.001) -> float32_156<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_151<1,128,30,80>\u001b[0m, float32_154<128>\u001b[0m, float32_155<128>\u001b[0m, float32_152<128>\u001b[0m, float32_153<128>\u001b[0m, False, 0.1, 0.001, True) -> float32_156<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_156<1,128,30,80>\u001b[0m) -> float32_156<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_156<1,128,30,80>\u001b[0m, inplace=128) -> float32_156<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_156<1,128,30,80>\u001b[0m) -> float32_156<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mDilatedParllelResidualBlockB[model.TwinLiteRELU]\u001b[0m(float32_156<1,128,30,80>\u001b[0m) -> float32_178<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mC[model.TwinLiteRELU]\u001b[0m(float32_156<1,128,30,80>\u001b[0m) -> float32_158<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_156<1,128,30,80>\u001b[0m) -> float32_158<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_156<1,128,30,80>\u001b[0m, float32_157<25,128,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_158<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_158<1,25,30,80>\u001b[0m) -> float32_160<1,28,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_158<1,25,30,80>\u001b[0m) -> float32_160<1,28,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_158<1,25,30,80>\u001b[0m, float32_159<28,25,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_160<1,28,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_158<1,25,30,80>\u001b[0m) -> float32_162<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_158<1,25,30,80>\u001b[0m) -> float32_162<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_158<1,25,30,80>\u001b[0m, float32_161<25,25,3,3>\u001b[0m, None, (1, 1), (2, 2), (2, 2), 1) -> float32_162<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_158<1,25,30,80>\u001b[0m) -> float32_164<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_158<1,25,30,80>\u001b[0m) -> float32_164<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_158<1,25,30,80>\u001b[0m, float32_163<25,25,3,3>\u001b[0m, None, (1, 1), (4, 4), (4, 4), 1) -> float32_164<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_158<1,25,30,80>\u001b[0m) -> float32_166<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_158<1,25,30,80>\u001b[0m) -> float32_166<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_158<1,25,30,80>\u001b[0m, float32_165<25,25,3,3>\u001b[0m, None, (1, 1), (8, 8), (8, 8), 1) -> float32_166<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCDilated[model.TwinLiteRELU]\u001b[0m(float32_158<1,25,30,80>\u001b[0m) -> float32_168<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_158<1,25,30,80>\u001b[0m) -> float32_168<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_158<1,25,30,80>\u001b[0m, float32_167<25,25,3,3>\u001b[0m, None, (1, 1), (16, 16), (16, 16), 1) -> float32_168<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_162<1,25,30,80>\u001b[0m, float32_164<1,25,30,80>\u001b[0m) -> float32_169<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_162<1,25,30,80>\u001b[0m, float32_164<1,25,30,80>\u001b[0m) -> float32_169<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_169<1,25,30,80>\u001b[0m, float32_166<1,25,30,80>\u001b[0m) -> float32_170<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_169<1,25,30,80>\u001b[0m, float32_166<1,25,30,80>\u001b[0m) -> float32_170<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_170<1,25,30,80>\u001b[0m, float32_168<1,25,30,80>\u001b[0m) -> float32_171<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_170<1,25,30,80>\u001b[0m, float32_168<1,25,30,80>\u001b[0m) -> float32_171<1,25,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_160<1,28,30,80>\u001b[0m, float32_162<1,25,30,80>\u001b[0m, float32_169<1,25,30,80>\u001b[0m, float32_170<1,25,30,80>\u001b[0m, float32_171<1,25,30,80>\u001b[0m], 1) -> float32_172<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_156<1,128,30,80>\u001b[0m, float32_172<1,128,30,80>\u001b[0m) -> float32_173<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_156<1,128,30,80>\u001b[0m, float32_172<1,128,30,80>\u001b[0m) -> float32_173<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mBR[model.TwinLiteRELU]\u001b[0m(float32_173<1,128,30,80>\u001b[0m) -> float32_178<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_173<1,128,30,80>\u001b[0m) -> float32_178<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_173<1,128,30,80>\u001b[0m, float32_174<128>\u001b[0m, float32_175<128>\u001b[0m, float32_176<128>\u001b[0m, float32_177<128>\u001b[0m, False, 0.1, 0.001) -> float32_178<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_173<1,128,30,80>\u001b[0m, float32_176<128>\u001b[0m, float32_177<128>\u001b[0m, float32_174<128>\u001b[0m, float32_175<128>\u001b[0m, False, 0.1, 0.001, True) -> float32_178<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_178<1,128,30,80>\u001b[0m) -> float32_178<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_178<1,128,30,80>\u001b[0m, inplace=128) -> float32_178<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_178<1,128,30,80>\u001b[0m) -> float32_178<1,128,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_112<1,128,30,80>\u001b[0m, float32_178<1,128,30,80>\u001b[0m], 1) -> float32_179<1,256,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCBR[model.TwinLiteRELU]\u001b[0m(float32_179<1,256,30,80>\u001b[0m) -> float32_186<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_179<1,256,30,80>\u001b[0m) -> float32_181<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_179<1,256,30,80>\u001b[0m, float32_180<32,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_181<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_181<1,32,30,80>\u001b[0m) -> float32_186<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_181<1,32,30,80>\u001b[0m, float32_182<32>\u001b[0m, float32_183<32>\u001b[0m, float32_184<32>\u001b[0m, float32_185<32>\u001b[0m, False, 0.1, 0.001) -> float32_186<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_181<1,32,30,80>\u001b[0m, float32_184<32>\u001b[0m, float32_185<32>\u001b[0m, float32_182<32>\u001b[0m, float32_183<32>\u001b[0m, False, 0.1, 0.001, True) -> float32_186<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_186<1,32,30,80>\u001b[0m) -> float32_186<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_186<1,32,30,80>\u001b[0m, inplace=32) -> float32_186<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_186<1,32,30,80>\u001b[0m) -> float32_186<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mPAM_Module[model.TwinLiteRELU]\u001b[0m(float32_186<1,32,30,80>\u001b[0m) -> float32_207<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_186<1,32,30,80>\u001b[0m) -> float32_189<1,4,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_186<1,32,30,80>\u001b[0m, float32_187<4,32,1,1>\u001b[0m, float32_188<4>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_189<1,4,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_189<1,4,30,80>\u001b[0m, 1, -1, 2400) -> float32_190<1,4,2400>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_190<1,4,2400>\u001b[0m, 0, 2, 1) -> float32_191<1,2400,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_186<1,32,30,80>\u001b[0m) -> float32_194<1,4,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_186<1,32,30,80>\u001b[0m, float32_192<4,32,1,1>\u001b[0m, float32_193<4>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_194<1,4,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_194<1,4,30,80>\u001b[0m, 1, -1, 2400) -> float32_195<1,4,2400>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mbmm[torch]\u001b[0m(float32_191<1,2400,4>\u001b[0m, float32_195<1,4,2400>\u001b[0m) -> float32_196<1,2400,2400>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSoftmax[torch.nn.modules.activation]\u001b[0m(float32_196<1,2400,2400>\u001b[0m) -> float32_197<1,2400,2400>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1msoftmax[torch.nn.functional]\u001b[0m(float32_196<1,2400,2400>\u001b[0m, -1, _stacklevel=5) -> float32_197<1,2400,2400>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0msoftmax[torch.Tensor]\u001b[0m(float32_196<1,2400,2400>\u001b[0m, -1) -> float32_197<1,2400,2400>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_186<1,32,30,80>\u001b[0m) -> float32_200<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_186<1,32,30,80>\u001b[0m, float32_198<32,32,1,1>\u001b[0m, float32_199<32>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_200<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_200<1,32,30,80>\u001b[0m, 1, -1, 2400) -> float32_201<1,32,2400>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_197<1,2400,2400>\u001b[0m, 0, 2, 1) -> float32_202<1,2400,2400>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mbmm[torch]\u001b[0m(float32_201<1,32,2400>\u001b[0m, float32_202<1,2400,2400>\u001b[0m) -> float32_203<1,32,2400>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_203<1,32,2400>\u001b[0m, 1, 32, 30, 80) -> float32_204<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(\u001b[4mfloat32_205<1>\u001b[0m, float32_204<1,32,30,80>\u001b[0m) -> float32_206<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_205<1>\u001b[0m, float32_204<1,32,30,80>\u001b[0m) -> float32_206<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_206<1,32,30,80>\u001b[0m, float32_186<1,32,30,80>\u001b[0m) -> float32_207<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_206<1,32,30,80>\u001b[0m, float32_186<1,32,30,80>\u001b[0m) -> float32_207<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCBR[model.TwinLiteRELU]\u001b[0m(float32_207<1,32,30,80>\u001b[0m) -> float32_214<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_207<1,32,30,80>\u001b[0m) -> float32_209<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_207<1,32,30,80>\u001b[0m, float32_208<32,32,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_209<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_209<1,32,30,80>\u001b[0m) -> float32_214<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_209<1,32,30,80>\u001b[0m, float32_210<32>\u001b[0m, float32_211<32>\u001b[0m, float32_212<32>\u001b[0m, float32_213<32>\u001b[0m, False, 0.1, 0.001) -> float32_214<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_209<1,32,30,80>\u001b[0m, float32_212<32>\u001b[0m, float32_213<32>\u001b[0m, float32_210<32>\u001b[0m, float32_211<32>\u001b[0m, False, 0.1, 0.001, True) -> float32_214<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_214<1,32,30,80>\u001b[0m) -> float32_214<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_214<1,32,30,80>\u001b[0m, inplace=32) -> float32_214<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_214<1,32,30,80>\u001b[0m) -> float32_214<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCAM_Module[model.TwinLiteRELU]\u001b[0m(float32_186<1,32,30,80>\u001b[0m) -> float32_229<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_186<1,32,30,80>\u001b[0m, 1, 32, -1) -> float32_215<1,32,2400>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_186<1,32,30,80>\u001b[0m, 1, 32, -1) -> float32_216<1,32,2400>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_216<1,32,2400>\u001b[0m, 0, 2, 1) -> float32_217<1,2400,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mbmm[torch]\u001b[0m(float32_215<1,32,2400>\u001b[0m, float32_217<1,2400,32>\u001b[0m) -> float32_218<1,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mmax[torch]\u001b[0m(float32_218<1,32,32>\u001b[0m, -1, keepdim=True) -> (float32_219<1,32,1>\u001b[0m, \u001b[90mint64_220<1,32,1>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mexpand_as[torch.Tensor]\u001b[0m(float32_219<1,32,1>\u001b[0m, float32_218<1,32,32>\u001b[0m) -> float32_221<1,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__sub__[torch.Tensor]\u001b[0m(float32_221<1,32,32>\u001b[0m, float32_218<1,32,32>\u001b[0m) -> float32_222<1,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0msub[TensorBase]\u001b[0m(float32_221<1,32,32>\u001b[0m, float32_218<1,32,32>\u001b[0m) -> float32_222<1,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSoftmax[torch.nn.modules.activation]\u001b[0m(float32_222<1,32,32>\u001b[0m) -> float32_223<1,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1msoftmax[torch.nn.functional]\u001b[0m(float32_222<1,32,32>\u001b[0m, -1, _stacklevel=5) -> float32_223<1,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0msoftmax[torch.Tensor]\u001b[0m(float32_222<1,32,32>\u001b[0m, -1) -> float32_223<1,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_186<1,32,30,80>\u001b[0m, 1, 32, -1) -> float32_224<1,32,2400>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mbmm[torch]\u001b[0m(float32_223<1,32,32>\u001b[0m, float32_224<1,32,2400>\u001b[0m) -> float32_225<1,32,2400>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_225<1,32,2400>\u001b[0m, 1, 32, 30, 80) -> float32_226<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(\u001b[4mfloat32_227<1>\u001b[0m, float32_226<1,32,30,80>\u001b[0m) -> float32_228<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_227<1>\u001b[0m, float32_226<1,32,30,80>\u001b[0m) -> float32_228<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_228<1,32,30,80>\u001b[0m, float32_186<1,32,30,80>\u001b[0m) -> float32_229<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_228<1,32,30,80>\u001b[0m, float32_186<1,32,30,80>\u001b[0m) -> float32_229<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mCBR[model.TwinLiteRELU]\u001b[0m(float32_229<1,32,30,80>\u001b[0m) -> float32_236<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_229<1,32,30,80>\u001b[0m) -> float32_231<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_229<1,32,30,80>\u001b[0m, float32_230<32,32,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_231<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_231<1,32,30,80>\u001b[0m) -> float32_236<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_231<1,32,30,80>\u001b[0m, float32_232<32>\u001b[0m, float32_233<32>\u001b[0m, float32_234<32>\u001b[0m, float32_235<32>\u001b[0m, False, 0.1, 0.001) -> float32_236<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_231<1,32,30,80>\u001b[0m, float32_234<32>\u001b[0m, float32_235<32>\u001b[0m, float32_232<32>\u001b[0m, float32_233<32>\u001b[0m, False, 0.1, 0.001, True) -> float32_236<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_236<1,32,30,80>\u001b[0m) -> float32_236<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_236<1,32,30,80>\u001b[0m, inplace=32) -> float32_236<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_236<1,32,30,80>\u001b[0m) -> float32_236<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_214<1,32,30,80>\u001b[0m, float32_236<1,32,30,80>\u001b[0m) -> float32_237<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_214<1,32,30,80>\u001b[0m, float32_236<1,32,30,80>\u001b[0m) -> float32_237<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mCBR[model.TwinLiteRELU]\u001b[0m(float32_237<1,32,30,80>\u001b[0m) -> float32_244<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_237<1,32,30,80>\u001b[0m) -> float32_239<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_237<1,32,30,80>\u001b[0m, float32_238<32,32,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_239<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_239<1,32,30,80>\u001b[0m) -> float32_244<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_239<1,32,30,80>\u001b[0m, float32_240<32>\u001b[0m, float32_241<32>\u001b[0m, float32_242<32>\u001b[0m, float32_243<32>\u001b[0m, False, 0.1, 0.001) -> float32_244<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_239<1,32,30,80>\u001b[0m, float32_242<32>\u001b[0m, float32_243<32>\u001b[0m, float32_240<32>\u001b[0m, float32_241<32>\u001b[0m, False, 0.1, 0.001, True) -> float32_244<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_244<1,32,30,80>\u001b[0m) -> float32_244<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_244<1,32,30,80>\u001b[0m, inplace=32) -> float32_244<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_244<1,32,30,80>\u001b[0m) -> float32_244<1,32,30,80>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mUPx2[model.TwinLiteRELU]\u001b[0m(float32_244<1,32,30,80>\u001b[0m) -> float32_251<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConvTranspose2d[torch.nn.modules.conv]\u001b[0m(float32_244<1,32,30,80>\u001b[0m) -> float32_246<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv_transpose2d[torch.nn.functional]\u001b[0m(float32_244<1,32,30,80>\u001b[0m, float32_245<32,16,2,2>\u001b[0m, None, (2, 2), (0, 0), (0, 0), 1, (1, 1)) -> float32_246<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_246<1,16,60,160>\u001b[0m) -> float32_251<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_246<1,16,60,160>\u001b[0m, float32_247<16>\u001b[0m, float32_248<16>\u001b[0m, float32_249<16>\u001b[0m, float32_250<16>\u001b[0m, False, 0.1, 0.001) -> float32_251<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_246<1,16,60,160>\u001b[0m, float32_249<16>\u001b[0m, float32_250<16>\u001b[0m, float32_247<16>\u001b[0m, float32_248<16>\u001b[0m, False, 0.1, 0.001, True) -> float32_251<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_251<1,16,60,160>\u001b[0m) -> float32_251<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_251<1,16,60,160>\u001b[0m, inplace=16) -> float32_251<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_251<1,16,60,160>\u001b[0m) -> float32_251<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mUPx2[model.TwinLiteRELU]\u001b[0m(float32_251<1,16,60,160>\u001b[0m) -> float32_258<1,8,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConvTranspose2d[torch.nn.modules.conv]\u001b[0m(float32_251<1,16,60,160>\u001b[0m) -> float32_253<1,8,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv_transpose2d[torch.nn.functional]\u001b[0m(float32_251<1,16,60,160>\u001b[0m, float32_252<16,8,2,2>\u001b[0m, None, (2, 2), (0, 0), (0, 0), 1, (1, 1)) -> float32_253<1,8,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_253<1,8,120,320>\u001b[0m) -> float32_258<1,8,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_253<1,8,120,320>\u001b[0m, float32_254<8>\u001b[0m, float32_255<8>\u001b[0m, float32_256<8>\u001b[0m, float32_257<8>\u001b[0m, False, 0.1, 0.001) -> float32_258<1,8,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_253<1,8,120,320>\u001b[0m, float32_256<8>\u001b[0m, float32_257<8>\u001b[0m, float32_254<8>\u001b[0m, float32_255<8>\u001b[0m, False, 0.1, 0.001, True) -> float32_258<1,8,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_258<1,8,120,320>\u001b[0m) -> float32_258<1,8,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_258<1,8,120,320>\u001b[0m, inplace=8) -> float32_258<1,8,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_258<1,8,120,320>\u001b[0m) -> float32_258<1,8,120,320>\u001b[0m\n",
      "\u001b[32m ├·\u001b[0m \u001b[32mUPx2[model.TwinLiteRELU]\u001b[0m(float32_258<1,8,120,320>\u001b[0m) -> float32_265<1,2,240,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConvTranspose2d[torch.nn.modules.conv]\u001b[0m(float32_258<1,8,120,320>\u001b[0m) -> float32_260<1,2,240,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv_transpose2d[torch.nn.functional]\u001b[0m(float32_258<1,8,120,320>\u001b[0m, float32_259<8,2,2,2>\u001b[0m, None, (2, 2), (0, 0), (0, 0), 1, (1, 1)) -> float32_260<1,2,240,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_260<1,2,240,640>\u001b[0m) -> float32_265<1,2,240,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_260<1,2,240,640>\u001b[0m, float32_261<2>\u001b[0m, float32_262<2>\u001b[0m, float32_263<2>\u001b[0m, float32_264<2>\u001b[0m, False, 0.1, 0.001) -> float32_265<1,2,240,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_260<1,2,240,640>\u001b[0m, float32_263<2>\u001b[0m, float32_264<2>\u001b[0m, float32_261<2>\u001b[0m, float32_262<2>\u001b[0m, False, 0.1, 0.001, True) -> float32_265<1,2,240,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_265<1,2,240,640>\u001b[0m) -> float32_265<1,2,240,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_265<1,2,240,640>\u001b[0m, inplace=2) -> float32_265<1,2,240,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_265<1,2,240,640>\u001b[0m) -> float32_265<1,2,240,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mUPx2[model.TwinLiteRELU]\u001b[0m(float32_244<1,32,30,80>\u001b[0m) -> float32_272<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConvTranspose2d[torch.nn.modules.conv]\u001b[0m(float32_244<1,32,30,80>\u001b[0m) -> float32_267<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv_transpose2d[torch.nn.functional]\u001b[0m(float32_244<1,32,30,80>\u001b[0m, float32_266<32,16,2,2>\u001b[0m, None, (2, 2), (0, 0), (0, 0), 1, (1, 1)) -> float32_267<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_267<1,16,60,160>\u001b[0m) -> float32_272<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_267<1,16,60,160>\u001b[0m, float32_268<16>\u001b[0m, float32_269<16>\u001b[0m, float32_270<16>\u001b[0m, float32_271<16>\u001b[0m, False, 0.1, 0.001) -> float32_272<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_267<1,16,60,160>\u001b[0m, float32_270<16>\u001b[0m, float32_271<16>\u001b[0m, float32_268<16>\u001b[0m, float32_269<16>\u001b[0m, False, 0.1, 0.001, True) -> float32_272<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_272<1,16,60,160>\u001b[0m) -> float32_272<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_272<1,16,60,160>\u001b[0m, inplace=16) -> float32_272<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_272<1,16,60,160>\u001b[0m) -> float32_272<1,16,60,160>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mUPx2[model.TwinLiteRELU]\u001b[0m(float32_272<1,16,60,160>\u001b[0m) -> float32_279<1,8,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConvTranspose2d[torch.nn.modules.conv]\u001b[0m(float32_272<1,16,60,160>\u001b[0m) -> float32_274<1,8,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv_transpose2d[torch.nn.functional]\u001b[0m(float32_272<1,16,60,160>\u001b[0m, float32_273<16,8,2,2>\u001b[0m, None, (2, 2), (0, 0), (0, 0), 1, (1, 1)) -> float32_274<1,8,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_274<1,8,120,320>\u001b[0m) -> float32_279<1,8,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_274<1,8,120,320>\u001b[0m, float32_275<8>\u001b[0m, float32_276<8>\u001b[0m, float32_277<8>\u001b[0m, float32_278<8>\u001b[0m, False, 0.1, 0.001) -> float32_279<1,8,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_274<1,8,120,320>\u001b[0m, float32_277<8>\u001b[0m, float32_278<8>\u001b[0m, float32_275<8>\u001b[0m, float32_276<8>\u001b[0m, False, 0.1, 0.001, True) -> float32_279<1,8,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_279<1,8,120,320>\u001b[0m) -> float32_279<1,8,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_279<1,8,120,320>\u001b[0m, inplace=8) -> float32_279<1,8,120,320>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_279<1,8,120,320>\u001b[0m) -> float32_279<1,8,120,320>\u001b[0m\n",
      "\u001b[32m ├·\u001b[0m \u001b[32mUPx2[model.TwinLiteRELU]\u001b[0m(float32_279<1,8,120,320>\u001b[0m) -> float32_286<1,2,240,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConvTranspose2d[torch.nn.modules.conv]\u001b[0m(float32_279<1,8,120,320>\u001b[0m) -> float32_281<1,2,240,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv_transpose2d[torch.nn.functional]\u001b[0m(float32_279<1,8,120,320>\u001b[0m, float32_280<8,2,2,2>\u001b[0m, None, (2, 2), (0, 0), (0, 0), 1, (1, 1)) -> float32_281<1,2,240,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_281<1,2,240,640>\u001b[0m) -> float32_286<1,2,240,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_281<1,2,240,640>\u001b[0m, float32_282<2>\u001b[0m, float32_283<2>\u001b[0m, float32_284<2>\u001b[0m, float32_285<2>\u001b[0m, False, 0.1, 0.001) -> float32_286<1,2,240,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_281<1,2,240,640>\u001b[0m, float32_284<2>\u001b[0m, float32_285<2>\u001b[0m, float32_282<2>\u001b[0m, float32_283<2>\u001b[0m, False, 0.1, 0.001, True) -> float32_286<1,2,240,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_286<1,2,240,640>\u001b[0m) -> float32_286<1,2,240,640>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_286<1,2,240,640>\u001b[0m, inplace=2) -> float32_286<1,2,240,640>\u001b[0m\n",
      "\u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_286<1,2,240,640>\u001b[0m) -> float32_286<1,2,240,640>\u001b[0m\n",
      "\n",
      "[Nobuco] Conversion complete. Elapsed time: 11.68 sec.\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 3, int(HEIGHT_FACTOR * dataset.H_), dataset.W_)\n",
    "keras_model = pytorch_to_keras(model, [input], inputs_channel_order=ChannelOrder.TENSORFLOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmprewvbcyt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmprewvbcyt/assets\n",
      "2024-08-20 10:42:20.864936: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-08-20 10:42:20.864980: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-08-20 10:42:20.866320: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmprewvbcyt\n",
      "2024-08-20 10:42:20.892758: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-08-20 10:42:20.892789: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmprewvbcyt\n",
      "2024-08-20 10:42:20.941032: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-08-20 10:42:20.960809: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-08-20 10:42:21.282074: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmprewvbcyt\n",
      "2024-08-20 10:42:21.440563: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 574248 microseconds.\n",
      "2024-08-20 10:42:21.650767: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 109, Total Ops 292, % non-converted = 37.33 %\n",
      " * 109 ARITH ops\n",
      "\n",
      "- arith.constant:  109 occurrences  (f32: 95, i32: 14)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 36)\n",
      "  (f32: 2)\n",
      "  (f32: 4)\n",
      "  (f32: 10)\n",
      "  (f32: 52)\n",
      "  (f32: 10)\n",
      "  (f32: 44)\n",
      "  (f32: 1)\n",
      "  (f32: 6)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 6)\n",
      "  (f32: 6)\n",
      "2024-08-20 10:42:22.021726: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 5.345 G  ops, equivalently 2.673 G  MACs\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "with open(f\"models/twinlitenet.tflite\", 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp44c2wt1k/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp44c2wt1k/assets\n",
      "/home/ubuntadmin/Desktop/TwinLiteNet/venv/lib/python3.11/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-08-20 10:42:40.402823: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-08-20 10:42:40.402851: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-08-20 10:42:40.403029: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp44c2wt1k\n",
      "2024-08-20 10:42:40.426022: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-08-20 10:42:40.426064: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp44c2wt1k\n",
      "2024-08-20 10:42:40.485395: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-08-20 10:42:40.798848: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp44c2wt1k\n",
      "2024-08-20 10:42:40.948503: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 545476 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 109, Total Ops 292, % non-converted = 37.33 %\n",
      " * 109 ARITH ops\n",
      "\n",
      "- arith.constant:  109 occurrences  (f32: 95, i32: 14)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 36)\n",
      "  (f32: 2)\n",
      "  (f32: 4)\n",
      "  (f32: 10)\n",
      "  (f32: 52)\n",
      "  (f32: 10)\n",
      "  (f32: 44)\n",
      "  (f32: 1)\n",
      "  (f32: 6)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 6)\n",
      "  (f32: 6)\n",
      "2024-08-20 10:42:41.505613: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 5.345 G  ops, equivalently 2.673 G  MACs\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n",
      "2024-08-20 10:42:42.288352: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 5.345 G  ops, equivalently 2.673 G  MACs\n"
     ]
    }
   ],
   "source": [
    "def representative_dataset_gen():\n",
    "\tfor img_name, input, (seg_da, seg_ll) in tqdm(dataset):\n",
    "\t\tinput = input.float() / 255.0\n",
    "\t\tinput = input.numpy()\n",
    "\t\tinput = np.expand_dims(input, axis=0)\n",
    "\t\tinput = np.transpose(input, (0, 2, 3, 1))\n",
    "\n",
    "\t\tinput = input[:, int((1 - HEIGHT_FACTOR) * dataset.H_) :, :, :]\n",
    "\n",
    "\t\tyield [input]\n",
    "\n",
    "# DOES NOT WORK\n",
    "def random_representation_gen():\n",
    "\t# USE IMAGENET MEAN AND STD\n",
    "\tinput_transform_mean=[0.485, 0.456, 0.406]\n",
    "\tinput_transform_std=[0.229, 0.224, 0.225]\n",
    "\n",
    "\tinput = np.random.rand(1, dataset.H_, dataset.W_, 3)\n",
    "\tinput = input * input_transform_std + input_transform_mean\n",
    "\tyield [input.astype(np.float32)]\n",
    "\n",
    "qt_converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
    "qt_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "qt_converter.representative_dataset = representative_dataset_gen\n",
    "#qt_converter.representative_dataset = random_representation_gen\n",
    "\n",
    "tflite_model = qt_converter.convert()\n",
    "with open(f\"models/twinlitenet_qt.tflite\", 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
